{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a63842d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "mol = Chem.MolFromSmiles(\"CCO\")\n",
    "print(mol is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34340e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb version: 4.6.0 lib path: c:\\Users\\Wilf\\miniconda3\\Lib\\site-packages\\lightgbm\\__init__.py\n",
      "Looks like GPU option available.\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb, sys\n",
    "print(\"lgb version:\", lgb.__version__, \"lib path:\", lgb.__file__)\n",
    "try:\n",
    "    _ = lgb.LGBMClassifier(device='gpu')\n",
    "    print(\"Looks like GPU option available.\")\n",
    "except Exception as e:\n",
    "    print(\"No GPU support in this LightGBM build:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5261891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost GPU ready\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor', gpu_id=0)\n",
    "print(\"XGBoost GPU ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c3d1baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries loaded successfully!\n",
      "TensorFlow GPU available: []\n"
     ]
    }
   ],
   "source": [
    "import imblearn, xgboost, tensorflow as tf\n",
    "print(\"✅ All libraries loaded successfully!\")\n",
    "print(\"TensorFlow GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c798f049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 24 11:13:24 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 581.57                 Driver Version: 581.57         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   52C    P0             13W /  125W |    1180MiB /   8188MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            6524    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A            7224    C+G   ...kyb3d8bbwe\\EdgeGameAssist.exe      N/A      |\n",
      "|    0   N/A  N/A            9452    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13784    C+G   ...lpaper_engine\\wallpaper32.exe      N/A      |\n",
      "|    0   N/A  N/A           14920    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           14980    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A           15220    C+G   ...2txyewy\\CrossDeviceResume.exe      N/A      |\n",
      "|    0   N/A  N/A           15252    C+G   ...aries\\Win64\\EpicWebHelper.exe      N/A      |\n",
      "|    0   N/A  N/A           15484    C+G   ...es\\Getscreen.me\\getscreen.exe      N/A      |\n",
      "|    0   N/A  N/A           15948    C+G   ...ows\\System32\\NahimicSvc64.exe      N/A      |\n",
      "|    0   N/A  N/A           16556    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           17492    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           17500    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           18396    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           19184    C+G   ...4__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A           21392    C+G   ....0.3537.92\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           24220    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           24728    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           25840    C+G   ..._8wekyb3d8bbwe\\XboxPcTray.exe      N/A      |\n",
      "|    0   N/A  N/A           26504    C+G   ...cord\\app-1.0.9212\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A           27032    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           27480    C+G   ...ef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A           28752    C+G   ...s\\Win64\\EpicGamesLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A           28860    C+G   ...em_tray\\lghub_system_tray.exe      N/A      |\n",
      "|    0   N/A  N/A           29372    C+G   ...ktop\\EA Desktop\\EADesktop.exe      N/A      |\n",
      "|    0   N/A  N/A           30520    C+G   ...A Desktop\\EACefSubProcess.exe      N/A      |\n",
      "|    0   N/A  N/A           32192    C+G   ...26wp6bftszj\\TranslucentTB.exe      N/A      |\n",
      "|    0   N/A  N/A           33884    C+G   ...em32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A           33924    C+G   ...4__w2gh52qy24etm\\Nahimic3.exe      N/A      |\n",
      "|    0   N/A  N/A           35148    C+G   ....0.3537.92\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           36128    C+G   ...4__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A           37184    C+G   ....0.3537.92\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           37584    C+G   ...adeonsoftware\\AMDRSSrcExt.exe      N/A      |\n",
      "|    0   N/A  N/A           37728    C+G   ...onsoftware\\RadeonSoftware.exe      N/A      |\n",
      "|    0   N/A  N/A           37840    C+G   ...64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A           38476    C+G   ...99wrpcg\\ModernFlyoutsHost.exe      N/A      |\n",
      "|    0   N/A  N/A           39660    C+G   ...__8wekyb3d8bbwe\\XboxPcApp.exe      N/A      |\n",
      "|    0   N/A  N/A           40220    C+G   ...Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A           43304    C+G   ...Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A           43372    C+G   ....0.3537.92\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           45952    C+G   ....0.3537.92\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           45964    C+G   ...e\\dotnet\\PAD.Console.Host.exe      N/A      |\n",
      "|    0   N/A  N/A           47412    C+G   ...lare WARP\\Cloudflare WARP.exe      N/A      |\n",
      "|    0   N/A  N/A           56396    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A           61844    C+G   ...yb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A           67480    C+G   ...ms\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A           71272    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "CatBoost GPU OK: True\n",
      "XGBoost GPU OK\n"
     ]
    }
   ],
   "source": [
    "# 1) confirm CUDA GPU visible\n",
    "!nvidia-smi\n",
    "\n",
    "# 2) test CatBoost GPU\n",
    "from catboost import CatBoostClassifier\n",
    "print(\"CatBoost GPU OK:\", CatBoostClassifier(task_type='GPU', devices='0').get_params() is not None)\n",
    "\n",
    "# 3) test XGBoost GPU\n",
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor', gpu_id=0)\n",
    "print(\"XGBoost GPU OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5505ef46-6b72-4dd1-92a0-444fa0f29922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\wilf\\miniconda3\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\wilf\\miniconda3\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\wilf\\miniconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wilf\\miniconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\wilf\\miniconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wilf\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Loading reference_database(Hepato).xlsx\n",
      "Sheets: ['Sheet1']\n",
      "Initial shape: (2384, 5)\n",
      "Columns: ['Compound', 'Smiles', 'Label', 'Dataset', 'SMILES']\n",
      "Using SMILES column: Smiles\n",
      "Using label column: Label\n",
      "\n",
      "Sample entries (SMILES, label):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC1CC2OC(=O)C(=C)C2CC2(C)C(O)OC(O)CC12</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC=C(C)C(=O)OC1CCN2CC=C(COC(=O)C(O)(C(C)OC(C)=...</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC12CC3OC(=O)C(=C)C3CC1C(=C)CCC2O</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(C)C(O)(C(C)O)C(=O)OCC1=CCN2CCC(OC(C)=O)C12</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(CO)=C1CC=C(C)CCC=C(C)CC1=O</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CC(O)C1(O)CC(C)C(C)(OC(C)=O)C(=O)OCC2=CCN(C)CC...</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CC(=C)C1CC(CCC1(C)C=C)C(C)(C)O</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CC(C)C1(O)CC(=O)OC(C)C(O)(C(C)C)C(=O)OCC2=CCN3...</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Smiles Label\n",
       "0             CC1CC2OC(=O)C(=C)C2CC2(C)C(O)OC(O)CC12   Pos\n",
       "1  CC=C(C)C(=O)OC1CCN2CC=C(COC(=O)C(O)(C(C)OC(C)=...   Pos\n",
       "2                  CC12CC3OC(=O)C(=C)C3CC1C(=C)CCC2O   Pos\n",
       "3      CC(C)C(O)(C(C)O)C(=O)OCC1=CCN2CCC(OC(C)=O)C12   Pos\n",
       "4                      CC(CO)=C1CC=C(C)CCC=C(C)CC1=O   Pos\n",
       "5  CC(O)C1(O)CC(C)C(C)(OC(C)=O)C(=O)OCC2=CCN(C)CC...   Pos\n",
       "6                     CC(=C)C1CC(CCC1(C)C=C)C(C)(C)O   Pos\n",
       "7  CC(C)C1(O)CC(=O)OC(C)C(O)(C(C)C)C(=O)OCC2=CCN3...   Pos"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows missing SMILES/labels. Remaining: 2384\n",
      "Label counts:\n",
      " label\n",
      "0    1211\n",
      "1    1173\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Morgan fingerprints: 100%|██████████| 2384/2384 [00:00<00:00, 6047.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 invalid SMILES. Remaining valid molecules: 2384\n",
      "Saved cleaned CSV: reference_database_preprocessed.csv\n",
      "X shape: (2384, 2048) y shape: (2384,)\n",
      "Train/test shapes: (1907, 2048) (477, 2048)\n",
      "\n",
      "Training Random Forest...\n",
      "Training MLPClassifier...\n",
      "Training SVM (this may be slow)...\n",
      "\n",
      "Model results summary:\n",
      "RandomForest: Accuracy=0.7170, F1=0.7228, ROC-AUC=0.7748\n",
      "MLP: Accuracy=0.6918, F1=0.6879, ROC-AUC=0.7419\n",
      "SVM: Accuracy=0.7044, F1=0.7186, ROC-AUC=0.7691\n",
      "\n",
      "Best model by ROC-AUC: RandomForest\n",
      "Saved best model to: best_hepatotoxicity_model.pkl\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report for best model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       242\n",
      "           1       0.70      0.75      0.72       235\n",
      "\n",
      "    accuracy                           0.72       477\n",
      "   macro avg       0.72      0.72      0.72       477\n",
      "weighted avg       0.72      0.72      0.72       477\n",
      "\n",
      "\n",
      "All done. Cleaned CSV: reference_database_preprocessed.csv\n",
      "Best model: RandomForest saved at best_hepatotoxicity_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Full preprocessing + fingerprinting + model training script\n",
    "# Requirements:\n",
    "#  pip install pandas numpy scikit-learn rdkit-pypi tqdm joblib matplotlib seaborn\n",
    "# Optional (better): pip install xgboost lightgbm\n",
    "\n",
    "%pip install pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --------- USER: set path to your uploaded Excel file ----------\n",
    "INPUT_XLSX = \"reference_database(Hepato).xlsx\"   # change if needed\n",
    "OUTPUT_CSV = \"reference_database_preprocessed.csv\"\n",
    "BEST_MODEL_PATH = \"best_hepatotoxicity_model.pkl\"\n",
    "\n",
    "# --------- Step 0: load the Excel file and inspect ----------\n",
    "print(\"Loading\", INPUT_XLSX)\n",
    "xls = pd.ExcelFile(INPUT_XLSX)\n",
    "print(\"Sheets:\", xls.sheet_names)\n",
    "\n",
    "# load first sheet (change sheet_name if needed)\n",
    "df = pd.read_excel(xls, sheet_name=xls.sheet_names[0])\n",
    "print(\"Initial shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# --------- Step 1: detect SMILES and label columns ----------\n",
    "# heuristics to find likely SMILES and label columns\n",
    "smiles_cols = [c for c in df.columns if \"smile\" in c.lower()]\n",
    "label_candidates = [c for c in df.columns if any(x in c.lower() for x in [\"label\",\"final\",\"clean\",\"pos\",\"neg\",\"dili\",\"tox\"])]\n",
    "\n",
    "if not smiles_cols:\n",
    "    raise ValueError(\"No SMILES-like column found. Please rename your SMILES column to contain 'smile'.\")\n",
    "smiles_col = smiles_cols[0]\n",
    "print(\"Using SMILES column:\", smiles_col)\n",
    "\n",
    "# pick best label column if exists\n",
    "label_col = None\n",
    "preferred = [\"label_clean\",\"final_label\",\"label_numeric\",\"label\",\"label_raw\",\"label_bin\"]\n",
    "for p in preferred:\n",
    "    if p in df.columns:\n",
    "        label_col = p\n",
    "        break\n",
    "if label_col is None:\n",
    "    # fallback to first candidate if any\n",
    "    label_col = label_candidates[0] if label_candidates else None\n",
    "\n",
    "if label_col is None:\n",
    "    raise ValueError(\"No label-like column found. Please provide a column that indicates Pos/Neg or numeric labels.\")\n",
    "print(\"Using label column:\", label_col)\n",
    "\n",
    "# --------- Step 2: simple inspection ----------\n",
    "print(\"\\nSample entries (SMILES, label):\")\n",
    "display(df[[smiles_col, label_col]].head(8))\n",
    "\n",
    "# --------- Step 3: map labels to binary 1 (Pos) / 0 (Neg) ----------\n",
    "def map_label(v):\n",
    "    # handle lists or strings like \"['Pos']\" etc.\n",
    "    if pd.isna(v):\n",
    "        return None\n",
    "    # if list-like (some Excel imports might show python-list objects), handle them:\n",
    "    if isinstance(v, (list, tuple, set)):\n",
    "        s = str(v).lower()\n",
    "    else:\n",
    "        s = str(v).strip().lower()\n",
    "    # check common positive signs\n",
    "    if s in [\"1\", \"1.0\", \"[1]\", \"['1']\", \"true\", \"t\", \"pos\", \"positive\", \"p\", \"yes\", \"y\"] or \"pos\" in s or \"1\" in s and \"[-1]\" not in s:\n",
    "        return 1\n",
    "    if s in [\"0\", \"0.0\", \"-1\", \"[-1]\", \"['-1']\", \"neg\", \"negative\", \"n\", \"no\", \"false\", \"f\"] or \"neg\" in s or \"-1\" in s:\n",
    "        # treat -1 as negative (0)\n",
    "        return 0\n",
    "    # if it's numeric\n",
    "    try:\n",
    "        num = float(s)\n",
    "        return 1 if num > 0 else 0\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['label_mapped'] = df[label_col].apply(map_label)\n",
    "\n",
    "before_drop = len(df)\n",
    "# drop rows without SMILES or mapped label\n",
    "df = df.dropna(subset=[smiles_col, 'label_mapped'])\n",
    "df = df[df[smiles_col].astype(str).str.strip() != \"\"]\n",
    "print(f\"Dropped {before_drop - len(df)} rows missing SMILES/labels. Remaining: {len(df)}\")\n",
    "df = df.rename(columns={smiles_col: 'smiles'})\n",
    "df['label'] = df['label_mapped'].astype(int)\n",
    "\n",
    "print(\"Label counts:\\n\", df['label'].value_counts())\n",
    "\n",
    "# --------- Step 4: generate Morgan fingerprints (2048 bits) ----------\n",
    "tqdm.pandas(desc=\"Generating Morgan fingerprints\")\n",
    "morgan_gen = GetMorganGenerator(radius=2, fpSize=2048)\n",
    "\n",
    "def smiles_to_fp_array(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        fp = morgan_gen.GetFingerprint(mol)\n",
    "        arr = np.zeros((2048,), dtype=np.int8)\n",
    "        DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "        return arr\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "df['fingerprint'] = df['smiles'].progress_apply(smiles_to_fp_array)\n",
    "before_valid = len(df)\n",
    "df = df.dropna(subset=['fingerprint'])\n",
    "print(f\"Dropped {before_valid - len(df)} invalid SMILES. Remaining valid molecules: {len(df)}\")\n",
    "\n",
    "# save cleaned file (smiles + label)\n",
    "df[['smiles','label']].to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"Saved cleaned CSV:\", OUTPUT_CSV)\n",
    "\n",
    "# --------- Step 5: prepare X,y and train/test split ----------\n",
    "X = np.stack(df['fingerprint'].values)  # shape (n_samples, 2048)\n",
    "y = df['label'].values\n",
    "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
    "\n",
    "# stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"Train/test shapes:\", X_train.shape, X_test.shape)\n",
    "\n",
    "# --------- Step 6: train baseline models and evaluate ----------\n",
    "results = {}\n",
    "\n",
    "# 6A: Random Forest baseline\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:,1]\n",
    "results['RandomForest'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'f1': f1_score(y_test, y_pred_rf),\n",
    "    'roc_auc': roc_auc_score(y_test, y_prob_rf),\n",
    "    'report': classification_report(y_test, y_pred_rf, output_dict=True)\n",
    "}\n",
    "\n",
    "# 6B: MLP (sklearn)\n",
    "print(\"Training MLPClassifier...\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(512,256), max_iter=200, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "y_prob_mlp = mlp.predict_proba(X_test)[:,1]\n",
    "results['MLP'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_mlp),\n",
    "    'f1': f1_score(y_test, y_pred_mlp),\n",
    "    'roc_auc': roc_auc_score(y_test, y_prob_mlp),\n",
    "    'report': classification_report(y_test, y_pred_mlp, output_dict=True)\n",
    "}\n",
    "\n",
    "# 6C: SVM (RBF) - can be slower; if dataset is large, consider subsampling or use linear kernel\n",
    "print(\"Training SVM (this may be slow)...\")\n",
    "svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "y_prob_svm = svm.predict_proba(X_test)[:,1]\n",
    "results['SVM'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_svm),\n",
    "    'f1': f1_score(y_test, y_pred_svm),\n",
    "    'roc_auc': roc_auc_score(y_test, y_prob_svm),\n",
    "    'report': classification_report(y_test, y_pred_svm, output_dict=True)\n",
    "}\n",
    "\n",
    "# --------- Step 7: choose best model by ROC-AUC and save ----------\n",
    "best_model_name = max(results.keys(), key=lambda k: results[k]['roc_auc'])\n",
    "print(\"\\nModel results summary:\")\n",
    "for k,v in results.items():\n",
    "    print(f\"{k}: Accuracy={v['accuracy']:.4f}, F1={v['f1']:.4f}, ROC-AUC={v['roc_auc']:.4f}\")\n",
    "\n",
    "print(\"\\nBest model by ROC-AUC:\", best_model_name)\n",
    "best_model = {'RandomForest': rf, 'MLP': mlp, 'SVM': svm}[best_model_name]\n",
    "\n",
    "joblib.dump(best_model, BEST_MODEL_PATH)\n",
    "print(\"Saved best model to:\", BEST_MODEL_PATH)\n",
    "\n",
    "# --------- Step 8: confusion matrix of best model ----------\n",
    "best_pred = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, best_pred)\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f\"Confusion Matrix - {best_model_name}\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()\n",
    "\n",
    "# Print detailed classification report for best model\n",
    "print(\"\\nClassification report for best model:\")\n",
    "print(classification_report(y_test, best_pred))\n",
    "\n",
    "# Done\n",
    "print(\"\\nAll done. Cleaned CSV:\", OUTPUT_CSV)\n",
    "print(\"Best model:\", best_model_name, \"saved at\", BEST_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba23bae-9ddd-43dd-9794-a37a6fd3425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename: train_lgb_cpu.py\n",
    "import os, joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.rdMolDescriptors import CalcTPSA\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "INPUT_XLSX = \"reference_database(Hepato).xlsx\"\n",
    "MODEL_OUT = \"stacked_lgb_model.pkl\"\n",
    "\n",
    "# --------- 0. Load + basic clean ----------\n",
    "df = pd.read_excel(INPUT_XLSX, sheet_name=0)\n",
    "# drop empty columns (like Unnamed)\n",
    "df = df.loc[:, df.notna().any(axis=0)]\n",
    "# try to detect SMILES and label columns\n",
    "if 'SMILES' in df.columns:\n",
    "    smiles_col = 'SMILES'\n",
    "elif 'smiles' in df.columns:\n",
    "    smiles_col = 'smiles'\n",
    "else:\n",
    "    # fallback: find column with many characters and parens (heuristic)\n",
    "    candidates = [c for c in df.columns if df[c].astype(str).str.contains('=', na=False).sum() > 0]\n",
    "    smiles_col = candidates[0] if candidates else df.columns[-1]\n",
    "\n",
    "label_col = None\n",
    "for c in df.columns:\n",
    "    if any(x in c.lower() for x in ['label','final','tox','dili','pos','neg']):\n",
    "        label_col = c\n",
    "        break\n",
    "if label_col is None:\n",
    "    label_col = 'Label' if 'Label' in df.columns else df.columns[1]\n",
    "\n",
    "df = df.dropna(subset=[smiles_col, label_col])\n",
    "df = df[df[smiles_col].astype(str).str.strip() != \"\"].reset_index(drop=True)\n",
    "\n",
    "def map_label(v):\n",
    "    s = str(v).strip().lower()\n",
    "    if 'pos' in s or s in ['1','1.0','true','t','yes','y','p']: return 1\n",
    "    if 'neg' in s or s in ['0','0.0','-1','false','f','no','n']: return 0\n",
    "    try:\n",
    "        return 1 if float(s) > 0 else 0\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['label'] = df[label_col].apply(map_label)\n",
    "df = df.dropna(subset=['label']).reset_index(drop=True)\n",
    "df['label'] = df['label'].astype(int)\n",
    "print(\"Samples:\", len(df), \"Pos/Neg:\", df['label'].value_counts().to_dict())\n",
    "\n",
    "# --------- 1. Fingerprints (count-based) + descriptors ----------\n",
    "morgan_gen = GetMorganGenerator(radius=2, countSimulation=True, fpSize=2048)\n",
    "\n",
    "def mol_descriptors(mol):\n",
    "    return [\n",
    "        Descriptors.ExactMolWt(mol),\n",
    "        Descriptors.MolLogP(mol),\n",
    "        CalcTPSA(mol),\n",
    "        Descriptors.NumHDonors(mol),\n",
    "        Descriptors.NumHAcceptors(mol),\n",
    "        Descriptors.NumRotatableBonds(mol)\n",
    "    ]\n",
    "\n",
    "fps = []\n",
    "descs = []\n",
    "valid_idx = []\n",
    "for i, s in enumerate(tqdm(df[smiles_col], desc=\"FP+desc\")):\n",
    "    mol = Chem.MolFromSmiles(str(s))\n",
    "    if mol is None:\n",
    "        continue\n",
    "    fp = morgan_gen.GetFingerprint(mol)\n",
    "    arr = np.zeros((2048,), dtype=np.int32)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    fps.append(arr)\n",
    "    descs.append(mol_descriptors(mol))\n",
    "    valid_idx.append(i)\n",
    "\n",
    "df = df.iloc[valid_idx].reset_index(drop=True)\n",
    "X_fp = np.vstack(fps)\n",
    "X_desc = np.array(descs, dtype=float)\n",
    "X = np.hstack([X_fp, X_desc])\n",
    "y = df['label'].values\n",
    "print(\"Feature matrix:\", X.shape)\n",
    "\n",
    "# --------- 2. Train/test split ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"Train/test:\", X_train.shape, X_test.shape)\n",
    "\n",
    "# --------- 3. Handle imbalance (optional) ----------\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTE:\", np.bincount(y_train_bal))\n",
    "\n",
    "# --------- 4. Quick LightGBM baseline (tuned defaults) ----------\n",
    "lgb_params = {\n",
    "    'n_estimators': 600,\n",
    "    'num_leaves': 127,\n",
    "    'learning_rate': 0.03,\n",
    "    'max_depth': 12,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'reg_alpha': 0.2,\n",
    "    'reg_lambda': 0.4,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "lgbm = lgb.LGBMClassifier(**lgb_params)\n",
    "# cross-val AUC quick check\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cv_auc = np.mean(cross_val_score(lgbm, X_train_bal, y_train_bal, cv=cv, scoring='roc_auc', n_jobs=3))\n",
    "print(f\"CV AUC (LGB quick): {cv_auc:.4f}\")\n",
    "\n",
    "# train LGB on balanced data\n",
    "lgbm.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# --------- 5. Feature selection from LGB importances ----------\n",
    "sel = SelectFromModel(lgbm, threshold='median', prefit=True)\n",
    "X_train_sel = sel.transform(X_train_bal)\n",
    "X_test_sel = sel.transform(X_test)\n",
    "print(\"Selected features:\", X_train_sel.shape[1])\n",
    "\n",
    "# --------- 6. Stacking (RF + LGB) ----------\n",
    "rf = RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42)\n",
    "final_lgb = lgb.LGBMClassifier(**{**lgb_params, 'n_estimators':400})\n",
    "estimators = [('rf', rf), ('lgb', final_lgb)]\n",
    "stack = StackingClassifier(estimators=estimators, final_estimator=lgb.LGBMClassifier(n_estimators=300, random_state=42), cv=cv, n_jobs=-1)\n",
    "stack.fit(X_train_sel, y_train_bal)\n",
    "\n",
    "# --------- 7. Evaluate ----------\n",
    "y_prob = stack.predict_proba(X_test_sel)[:,1]\n",
    "y_pred = stack.predict(X_test_sel)\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"Test Acc:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# --------- 8. Save model ----------\n",
    "joblib.dump({'selector': sel, 'stack': stack}, MODEL_OUT)\n",
    "print(\"Saved model to\", MODEL_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad55e6d7-5633-41b5-94a6-0c74c75c9145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[LightGBM] [Info] Number of positive: 938, number of negative: 969\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3850\n",
      "[LightGBM] [Info] Number of data points in the train set: 1907, number of used features: 1925\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491872 -> initscore=-0.032515\n",
      "[LightGBM] [Info] Start training from score -0.032515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best AUC: 0.7693543469051074 Best params: {'subsample': 0.8, 'num_leaves': 63, 'n_estimators': 1000, 'min_child_samples': 5, 'max_depth': -1, 'learning_rate': 0.1, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(objective='binary', n_jobs=-1, random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "  'num_leaves': [31, 63, 127],\n",
    "  'max_depth': [-1, 6, 10, 16],\n",
    "  'learning_rate': [0.01, 0.05, 0.1],\n",
    "  'n_estimators': [200, 500, 1000],\n",
    "  'min_child_samples': [5, 10, 20],\n",
    "  'subsample': [0.6, 0.8, 1.0],\n",
    "  'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rs = RandomizedSearchCV(lgbm, param_distributions=param_dist, n_iter=40, cv=cv,\n",
    "                        scoring='roc_auc', n_jobs=-1, random_state=42, verbose=1)\n",
    "rs.fit(X_train, y_train)\n",
    "print(\"Best AUC:\", rs.best_score_, \"Best params:\", rs.best_params_)\n",
    "best_lgb = rs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f3fe493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. Parsed 2384/2384 molecules. Saved -> reference_database(Hepato)_with_descs.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ---------- Compute descriptors (robust, avoids missing-column KeyError) ----------\n",
    "desc_rows = []\n",
    "valid_mask = []\n",
    "\n",
    "for s in df[smiles_col].astype(str):\n",
    "    mol = mol_from_smiles_safe(s)\n",
    "    if mol is None:\n",
    "        desc_rows.append({\n",
    "            \"ExactMolWt\": np.nan,\n",
    "            \"MolLogP\": np.nan,\n",
    "            \"TPSA\": np.nan,\n",
    "            \"NumHDonors\": np.nan,\n",
    "            \"NumHAcceptors\": np.nan,\n",
    "            \"NumRotatableBonds\": np.nan,\n",
    "            \"HeavyAtomCount\": np.nan\n",
    "        })\n",
    "        valid_mask.append(False)\n",
    "    else:\n",
    "        # ensure compute_rdkit_descs returns a dict with the same keys\n",
    "        desc_rows.append(compute_rdkit_descs(mol))\n",
    "        valid_mask.append(True)\n",
    "\n",
    "# build DataFrame and guarantee expected columns exist\n",
    "desc_df = pd.DataFrame(desc_rows)\n",
    "expected_cols = [\"ExactMolWt\", \"MolLogP\", \"TPSA\", \"NumHDonors\",\n",
    "                 \"NumHAcceptors\", \"NumRotatableBonds\", \"HeavyAtomCount\"]\n",
    "for c in expected_cols:\n",
    "    if c not in desc_df.columns:\n",
    "        desc_df[c] = np.nan\n",
    "\n",
    "# now safe to compute interactions (no KeyError)\n",
    "desc_df[\"LogP_over_MolWt\"] = desc_df[\"MolLogP\"] / (desc_df[\"ExactMolWt\"] + 1e-9)\n",
    "desc_df[\"TPSA_per_Heavy\"]  = desc_df[\"TPSA\"] / (desc_df[\"HeavyAtomCount\"] + 1e-9)\n",
    "desc_df[\"MolLogP\"] = desc_df[\"MolLogP\"].clip(-10, 10)\n",
    "\n",
    "# Robust scaling (same as before)\n",
    "scaler = RobustScaler()\n",
    "to_scale = [\n",
    "    \"ExactMolWt\", \"MolLogP\", \"TPSA\", \"NumHDonors\",\n",
    "    \"NumHAcceptors\", \"NumRotatableBonds\", \"HeavyAtomCount\",\n",
    "    \"LogP_over_MolWt\", \"TPSA_per_Heavy\"\n",
    "]\n",
    "# ensure to_scale columns exist\n",
    "for c in to_scale:\n",
    "    if c not in desc_df.columns:\n",
    "        desc_df[c] = np.nan\n",
    "\n",
    "scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(desc_df[to_scale].fillna(0)),  # fillna(0) to avoid scaler errors\n",
    "    columns=[c + \"_scaled\" for c in to_scale]\n",
    ")\n",
    "desc_df = pd.concat([desc_df, scaled], axis=1)\n",
    "\n",
    "# combine & save\n",
    "df[\"_mol_valid\"] = valid_mask\n",
    "final_df = pd.concat([df.reset_index(drop=True), desc_df.reset_index(drop=True)], axis=1)\n",
    "final_df.to_excel(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"✅ Done. Parsed {sum(valid_mask)}/{len(df)} molecules. Saved -> {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "edb775a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FP + Descriptor Gen: 100%|██████████| 2384/2384 [00:01<00:00, 1554.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final feature shape: (2384, 2057) | Samples: 2384 | Pos/Neg: [1211 1173]\n",
      "Class Weights: {0: 0.9840041279669762, 1: 1.0165245202558635}\n",
      "✅ Selected features: 2057\n",
      "🔁 Generating OOF for cat\n",
      "🔁 Generating OOF for xgb\n",
      "🔁 Generating OOF for lgb\n",
      "\n",
      "📊 STACKED PERFORMANCE:\n",
      "ROC-AUC: 0.7689643045542466\n",
      "Accuracy: 0.6708595387840671\n",
      "Best F1: 0.7221238938053097 | Threshold: 0.3261176310945639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.48      0.60       242\n",
      "           1       0.62      0.87      0.72       235\n",
      "\n",
      "    accuracy                           0.67       477\n",
      "   macro avg       0.70      0.67      0.66       477\n",
      "weighted avg       0.70      0.67      0.66       477\n",
      "\n",
      "\n",
      "✅ Saved model → best_ensemble_final.pkl\n"
     ]
    }
   ],
   "source": [
    "# upgraded_pipeline_with_descs_and_stack_fixed.py\n",
    "# ✅ Final tuned pipeline for Hepato dataset with descriptor scaling + stacking ensemble.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.rdMolDescriptors import CalcTPSA\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, classification_report, precision_recall_curve\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.base import clone\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# -------------------- CONFIG --------------------\n",
    "LOAD_PATH = \"reference_database(Hepato)_with_descs_fixed.xlsx\"\n",
    "FP_SIZE = 1024\n",
    "R2, R3 = 2, 3\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# -------------------- HELPERS --------------------\n",
    "def mol_from_smiles_safe(s):\n",
    "    try:\n",
    "        return Chem.MolFromSmiles(str(s))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def compute_rdkit_descs(mol):\n",
    "    \"\"\"Return descriptor list for Mol object.\"\"\"\n",
    "    return [\n",
    "        float(Descriptors.ExactMolWt(mol)),\n",
    "        float(Descriptors.MolLogP(mol)),\n",
    "        float(CalcTPSA(mol)),\n",
    "        float(Descriptors.NumHDonors(mol)),\n",
    "        float(Descriptors.NumHAcceptors(mol)),\n",
    "        float(Descriptors.NumRotatableBonds(mol)),\n",
    "        float(mol.GetNumHeavyAtoms())\n",
    "    ]\n",
    "\n",
    "def map_label(v):\n",
    "    s = str(v).strip().lower()\n",
    "    if s in ['pos', 'positive', 'yes', 'y', 'true', '1', 'p']:\n",
    "        return 1\n",
    "    elif s in ['neg', 'negative', 'no', 'n', 'false', '0']:\n",
    "        return 0\n",
    "    else:\n",
    "        try:\n",
    "            return int(float(s))\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "# -------------------- LOAD DATA --------------------\n",
    "df = pd.read_excel(LOAD_PATH, sheet_name=0)\n",
    "label_col = next((c for c in df.columns if any(x in c.lower() for x in ['label', 'tox', 'final', 'dili', 'class'])), None)\n",
    "smiles_col = next((c for c in df.columns if 'smile' in c.lower()), None)\n",
    "\n",
    "if label_col is None or smiles_col is None:\n",
    "    raise RuntimeError(\"❌ Couldn't find SMILES or label columns. Please ensure correct naming.\")\n",
    "\n",
    "df[label_col] = df[label_col].apply(map_label)\n",
    "df = df.dropna(subset=[label_col, smiles_col]).reset_index(drop=True)\n",
    "df[label_col] = df[label_col].astype(int)\n",
    "\n",
    "# -------------------- FEATURES --------------------\n",
    "m2 = GetMorganGenerator(radius=R2, fpSize=FP_SIZE, countSimulation=True)\n",
    "m3 = GetMorganGenerator(radius=R3, fpSize=FP_SIZE, countSimulation=True)\n",
    "\n",
    "fps, descs, valid_idx = [], [], []\n",
    "\n",
    "for i, s in enumerate(tqdm(df[smiles_col], desc=\"FP + Descriptor Gen\")):\n",
    "    mol = mol_from_smiles_safe(s)\n",
    "    if mol is None:\n",
    "        continue\n",
    "    a2 = np.zeros((FP_SIZE,), dtype=np.int32)\n",
    "    a3 = np.zeros((FP_SIZE,), dtype=np.int32)\n",
    "    DataStructs.ConvertToNumpyArray(m2.GetFingerprint(mol), a2)\n",
    "    DataStructs.ConvertToNumpyArray(m3.GetFingerprint(mol), a3)\n",
    "    fps.append(np.hstack([a2, a3]))\n",
    "    descs.append(compute_rdkit_descs(mol))\n",
    "    valid_idx.append(i)\n",
    "\n",
    "df = df.iloc[valid_idx].reset_index(drop=True)\n",
    "X_fp = np.vstack(fps)\n",
    "X_desc_raw = np.array(descs)\n",
    "\n",
    "# engineered descriptor interactions\n",
    "mol_wt = X_desc_raw[:, 0:1]\n",
    "mol_logp = np.clip(X_desc_raw[:, 1:2], -10, 10)\n",
    "tpsa = X_desc_raw[:, 2:3]\n",
    "heavy = X_desc_raw[:, 6:7]\n",
    "logp_over_wt = mol_logp / (mol_wt + 1e-9)\n",
    "tpsa_per_heavy = tpsa / (heavy + 1e-9)\n",
    "\n",
    "X_desc = np.hstack([X_desc_raw, logp_over_wt, tpsa_per_heavy])\n",
    "scaler = RobustScaler()\n",
    "X_desc_scaled = scaler.fit_transform(X_desc)\n",
    "\n",
    "# combine all\n",
    "X = np.hstack([X_fp.astype(float), X_desc_scaled])\n",
    "y = df[label_col].values\n",
    "print(f\"✅ Final feature shape: {X.shape} | Samples: {len(y)} | Pos/Neg: {np.bincount(y)}\")\n",
    "\n",
    "# -------------------- TRAIN/TEST SPLIT --------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------- CLASS WEIGHTS --------------------\n",
    "cw = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "cw_dict = {int(c): float(cw[i]) for i, c in enumerate(np.unique(y_train))}\n",
    "scale_pos_weight = cw_dict[0] / cw_dict[1]\n",
    "print(\"Class Weights:\", cw_dict)\n",
    "\n",
    "# -------------------- FEATURE SELECTION (LightGBM) --------------------\n",
    "lgb_params = dict(\n",
    "    n_estimators=800, learning_rate=0.03, max_depth=10,\n",
    "    class_weight=cw_dict, random_state=RANDOM_STATE, verbose=-1\n",
    ")\n",
    "lg_fs = lgb.LGBMClassifier(**lgb_params)\n",
    "lg_fs.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric=\"binary_logloss\",\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=80), lgb.log_evaluation(period=0)]\n",
    ")\n",
    "\n",
    "sel = SelectFromModel(lg_fs, threshold=\"median\", prefit=True)\n",
    "X_train_sel = sel.transform(X_train)\n",
    "X_test_sel = sel.transform(X_test)\n",
    "print(\"✅ Selected features:\", X_train_sel.shape[1])\n",
    "\n",
    "# -------------------- BASE MODELS --------------------\n",
    "cat = CatBoostClassifier(\n",
    "    iterations=900, learning_rate=0.03, depth=7,\n",
    "    class_weights=list(cw), random_seed=RANDOM_STATE, verbose=0\n",
    ")\n",
    "xg = xgb.XGBClassifier(\n",
    "    n_estimators=800, learning_rate=0.03, max_depth=8,\n",
    "    scale_pos_weight=scale_pos_weight, eval_metric=\"logloss\", random_state=RANDOM_STATE\n",
    ")\n",
    "lgb_final = lgb.LGBMClassifier(**lgb_params)\n",
    "\n",
    "# -------------------- STACKING --------------------\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "oof_preds = np.zeros((X_train_sel.shape[0], 3))\n",
    "test_preds = np.zeros((X_test_sel.shape[0], 3))\n",
    "\n",
    "for i, (name, est) in enumerate([('cat', cat), ('xgb', xg), ('lgb', lgb_final)]):\n",
    "    print(f\"🔁 Generating OOF for {name}\")\n",
    "    oof = np.zeros(X_train_sel.shape[0])\n",
    "    test_fold = np.zeros((X_test_sel.shape[0], N_SPLITS))\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train_sel, y_train)):\n",
    "        X_tr, X_val = X_train_sel[tr_idx], X_train_sel[val_idx]\n",
    "        y_tr, y_val = y_train[tr_idx], y_train[val_idx]\n",
    "        e = clone(est)\n",
    "        e.fit(X_tr, y_tr)\n",
    "        oof[val_idx] = e.predict_proba(X_val)[:, 1]\n",
    "        test_fold[:, fold] = e.predict_proba(X_test_sel)[:, 1]\n",
    "\n",
    "    oof_preds[:, i] = oof\n",
    "    test_preds[:, i] = test_fold.mean(axis=1)\n",
    "\n",
    "# -------------------- META-MODEL --------------------\n",
    "meta = LogisticRegression(max_iter=3000, class_weight='balanced', random_state=RANDOM_STATE)\n",
    "meta.fit(oof_preds, y_train)\n",
    "meta_test_preds = meta.predict_proba(test_preds)[:, 1]\n",
    "\n",
    "# threshold tuning\n",
    "p, r, th = precision_recall_curve(y_test, meta_test_preds)\n",
    "f1s = 2 * p * r / (p + r + 1e-12)\n",
    "best_thr = float(th[np.nanargmax(f1s)]) if len(th) > 0 else 0.5\n",
    "y_pred = (meta_test_preds >= best_thr).astype(int)\n",
    "\n",
    "print(\"\\n📊 STACKED PERFORMANCE:\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, meta_test_preds))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Best F1:\", f1_score(y_test, y_pred), \"| Threshold:\", best_thr)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# -------------------- SAVE ARTIFACT --------------------\n",
    "artifact = {\n",
    "    \"selector\": sel,\n",
    "    \"scaler\": scaler,\n",
    "    \"meta\": meta,\n",
    "    \"threshold\": best_thr,\n",
    "    \"fp_params\": {\"radius2\": R2, \"radius3\": R3, \"fp_size\": FP_SIZE},\n",
    "    \"base_models\": {\n",
    "        \"cat\": cat.fit(X_train_sel, y_train),\n",
    "        \"xgb\": xg.fit(X_train_sel, y_train),\n",
    "        \"lgb\": lgb_final.fit(X_train_sel, y_train)\n",
    "    }\n",
    "}\n",
    "\n",
    "joblib.dump(artifact, \"best_ensemble_final.pkl\")\n",
    "print(\"\\n✅ Saved model → best_ensemble_final.pkl\")\n",
    "\n",
    "# -------------------- INFERENCE --------------------\n",
    "def compute_features_for_smiles(smiles_list):\n",
    "    fps, descs = [], []\n",
    "    for s in smiles_list:\n",
    "        mol = mol_from_smiles_safe(s)\n",
    "        if mol is None:\n",
    "            fps.append(np.zeros((FP_SIZE * 2,), dtype=float))\n",
    "            descs.append([0.0] * 9)\n",
    "            continue\n",
    "        a2 = np.zeros((FP_SIZE,), dtype=np.int32)\n",
    "        a3 = np.zeros((FP_SIZE,), dtype=np.int32)\n",
    "        DataStructs.ConvertToNumpyArray(m2.GetFingerprint(mol), a2)\n",
    "        DataStructs.ConvertToNumpyArray(m3.GetFingerprint(mol), a3)\n",
    "        fps.append(np.hstack([a2, a3]).astype(float))\n",
    "        rd = compute_rdkit_descs(mol)\n",
    "        logp_over_wt = rd[1] / (rd[0] + 1e-9)\n",
    "        tpsa_per_heavy = rd[2] / (rd[6] + 1e-9)\n",
    "        descs.append(rd + [logp_over_wt, tpsa_per_heavy])\n",
    "    X_fp_new = np.vstack(fps)\n",
    "    X_desc_new = np.array(descs, dtype=float)\n",
    "    X_desc_new[:, 1] = np.clip(X_desc_new[:, 1], -10, 10)\n",
    "    X_desc_new_scaled = scaler.transform(X_desc_new)\n",
    "    X_new = np.hstack([X_fp_new, X_desc_new_scaled])\n",
    "    return sel.transform(X_new)\n",
    "\n",
    "def predict_from_smiles(smiles_list):\n",
    "    art = joblib.load(\"best_ensemble_final.pkl\")\n",
    "    X_sel = compute_features_for_smiles(smiles_list)\n",
    "    base = art[\"base_models\"]\n",
    "    probs = np.zeros((X_sel.shape[0], 3))\n",
    "    probs[:, 0] = base[\"cat\"].predict_proba(X_sel)[:, 1]\n",
    "    probs[:, 1] = base[\"xgb\"].predict_proba(X_sel)[:, 1]\n",
    "    probs[:, 2] = base[\"lgb\"].predict_proba(X_sel)[:, 1]\n",
    "    meta = art[\"meta\"]\n",
    "    final_probs = meta.predict_proba(probs)[:, 1]\n",
    "    preds = (final_probs >= art[\"threshold\"]).astype(int)\n",
    "    return final_probs, preds\n",
    "\n",
    "# Example:\n",
    "# final_probs, preds = predict_from_smiles([\"CCO\", \"c1ccccc1\", \"INVALID\"])\n",
    "# print(final_probs, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf16bc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced feature count: 574\n"
     ]
    }
   ],
   "source": [
    "# Replace current feature selection block with:\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lg_fs = lgb.LGBMClassifier(**lgb_params)\n",
    "lg_fs.fit(X_train, y_train, eval_set=[(X_test, y_test)],\n",
    "          eval_metric='binary_logloss',\n",
    "          callbacks=[lgb.early_stopping(stopping_rounds=60), lgb.log_evaluation(period=0)])\n",
    "\n",
    "# Get feature importances\n",
    "importances = lg_fs.feature_importances_\n",
    "threshold_value = np.percentile(importances, 75)  # top 25% important features\n",
    "sel = SelectFromModel(lg_fs, threshold=threshold_value, prefit=True)\n",
    "X_train_sel = sel.transform(X_train)\n",
    "X_test_sel  = sel.transform(X_test)\n",
    "print(\"Reduced feature count:\", X_train_sel.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ba995f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Descriptors\n",
    "extra_descs = [\n",
    "    Descriptors.FractionCSP3(mol),\n",
    "    Descriptors.RingCount(mol),\n",
    "    Descriptors.NHOHCount(mol),\n",
    "    Descriptors.NOCount(mol),\n",
    "    Descriptors.NumAromaticRings(mol)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "977e1245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:49:12,673] A new study created in memory with name: no-name-aa87aa40-43a6-470b-b7b0-7c1ea09c03e2\n",
      "[I 2025-10-24 12:49:13,272] Trial 0 finished with value: 0.6795698924731183 and parameters: {'n_estimators': 722, 'num_leaves': 35, 'learning_rate': 0.06555800876647468, 'max_depth': 11, 'min_child_samples': 30, 'subsample': 0.6824379096881423, 'colsample_bytree': 0.9027990934883506, 'reg_alpha': 0.5283627061519416, 'reg_lambda': 0.1544056771773863}. Best is trial 0 with value: 0.6795698924731183.\n",
      "[I 2025-10-24 12:49:14,493] Trial 1 finished with value: 0.6795698924731183 and parameters: {'n_estimators': 1085, 'num_leaves': 39, 'learning_rate': 0.015219603059690025, 'max_depth': 14, 'min_child_samples': 31, 'subsample': 0.6805902724821178, 'colsample_bytree': 0.9721165920656993, 'reg_alpha': 0.28770659140400134, 'reg_lambda': 0.671827038576164}. Best is trial 0 with value: 0.6795698924731183.\n",
      "[I 2025-10-24 12:49:15,010] Trial 2 finished with value: 0.6924731182795699 and parameters: {'n_estimators': 675, 'num_leaves': 33, 'learning_rate': 0.020209977502879645, 'max_depth': 13, 'min_child_samples': 54, 'subsample': 0.6548403122139934, 'colsample_bytree': 0.6294511862567542, 'reg_alpha': 0.25884281809554155, 'reg_lambda': 0.9013946463595562}. Best is trial 2 with value: 0.6924731182795699.\n",
      "[I 2025-10-24 12:49:15,447] Trial 3 finished with value: 0.6710816777041942 and parameters: {'n_estimators': 761, 'num_leaves': 88, 'learning_rate': 0.09574183777267142, 'max_depth': 13, 'min_child_samples': 60, 'subsample': 0.8569751763744455, 'colsample_bytree': 0.656224531859653, 'reg_alpha': 0.49889675792310184, 'reg_lambda': 0.5015804479390277}. Best is trial 2 with value: 0.6924731182795699.\n",
      "[I 2025-10-24 12:49:16,511] Trial 4 finished with value: 0.6681034482758621 and parameters: {'n_estimators': 965, 'num_leaves': 120, 'learning_rate': 0.029462969561466865, 'max_depth': 8, 'min_child_samples': 14, 'subsample': 0.7322879933337528, 'colsample_bytree': 0.921365030426296, 'reg_alpha': 0.7334727095922696, 'reg_lambda': 0.791443600654987}. Best is trial 2 with value: 0.6924731182795699.\n",
      "[I 2025-10-24 12:49:17,258] Trial 5 finished with value: 0.7016806722689075 and parameters: {'n_estimators': 921, 'num_leaves': 101, 'learning_rate': 0.023900521549360454, 'max_depth': 8, 'min_child_samples': 28, 'subsample': 0.8966084715813978, 'colsample_bytree': 0.8275400285591212, 'reg_alpha': 0.4884094828732616, 'reg_lambda': 0.9498436227759033}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:17,994] Trial 6 finished with value: 0.6905263157894737 and parameters: {'n_estimators': 771, 'num_leaves': 115, 'learning_rate': 0.010889876050181076, 'max_depth': 7, 'min_child_samples': 14, 'subsample': 0.9997358120688389, 'colsample_bytree': 0.8929296478801809, 'reg_alpha': 0.0875756178934125, 'reg_lambda': 0.9892950130158742}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:18,940] Trial 7 finished with value: 0.6893617021276596 and parameters: {'n_estimators': 939, 'num_leaves': 107, 'learning_rate': 0.012398842981445361, 'max_depth': 13, 'min_child_samples': 31, 'subsample': 0.687639414460607, 'colsample_bytree': 0.7242930520611967, 'reg_alpha': 0.5758740574567828, 'reg_lambda': 0.9742066212855643}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:19,353] Trial 8 finished with value: 0.6896551724137931 and parameters: {'n_estimators': 837, 'num_leaves': 82, 'learning_rate': 0.09452730718141043, 'max_depth': 6, 'min_child_samples': 59, 'subsample': 0.8352878853989565, 'colsample_bytree': 0.7369436888462814, 'reg_alpha': 0.0559788124724393, 'reg_lambda': 0.38153810472212024}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:19,783] Trial 9 finished with value: 0.6695095948827292 and parameters: {'n_estimators': 1113, 'num_leaves': 109, 'learning_rate': 0.0922602747025436, 'max_depth': 10, 'min_child_samples': 19, 'subsample': 0.7735398842106321, 'colsample_bytree': 0.9692774561289529, 'reg_alpha': 0.8061178186107308, 'reg_lambda': 0.295401771166672}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:20,112] Trial 10 finished with value: 0.676595744680851 and parameters: {'n_estimators': 401, 'num_leaves': 64, 'learning_rate': 0.044256166621276155, 'max_depth': 9, 'min_child_samples': 44, 'subsample': 0.9353735039534817, 'colsample_bytree': 0.8263746241592579, 'reg_alpha': 0.9500466458473147, 'reg_lambda': 0.011640275345374873}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:20,576] Trial 11 finished with value: 0.6924731182795699 and parameters: {'n_estimators': 488, 'num_leaves': 63, 'learning_rate': 0.03711574479321855, 'max_depth': 15, 'min_child_samples': 45, 'subsample': 0.6017885443754606, 'colsample_bytree': 0.6225802224397496, 'reg_alpha': 0.3032546678462653, 'reg_lambda': 0.7785078987443532}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:20,851] Trial 12 finished with value: 0.6780383795309168 and parameters: {'n_estimators': 583, 'num_leaves': 92, 'learning_rate': 0.05791395470304744, 'max_depth': 5, 'min_child_samples': 42, 'subsample': 0.894456392636548, 'colsample_bytree': 0.8111546562021082, 'reg_alpha': 0.3290263465265327, 'reg_lambda': 0.8162367044934646}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:21,322] Trial 13 finished with value: 0.6808510638297872 and parameters: {'n_estimators': 624, 'num_leaves': 57, 'learning_rate': 0.02789233466873084, 'max_depth': 11, 'min_child_samples': 52, 'subsample': 0.937668914184753, 'colsample_bytree': 0.7272043276346829, 'reg_alpha': 0.17925548592535923, 'reg_lambda': 0.630715695285123}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:22,002] Trial 14 finished with value: 0.6652267818574514 and parameters: {'n_estimators': 871, 'num_leaves': 97, 'learning_rate': 0.07045085068466526, 'max_depth': 12, 'min_child_samples': 23, 'subsample': 0.6247148583249256, 'colsample_bytree': 0.7707193058877585, 'reg_alpha': 0.41475167652908396, 'reg_lambda': 0.8975657014465751}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:22,783] Trial 15 finished with value: 0.6895074946466809 and parameters: {'n_estimators': 976, 'num_leaves': 51, 'learning_rate': 0.02584422951400844, 'max_depth': 9, 'min_child_samples': 38, 'subsample': 0.778870714787945, 'colsample_bytree': 0.8529459094209848, 'reg_alpha': 0.6184951185428329, 'reg_lambda': 0.6406043832625526}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:23,369] Trial 16 finished with value: 0.691304347826087 and parameters: {'n_estimators': 640, 'num_leaves': 73, 'learning_rate': 0.04564206869124013, 'max_depth': 7, 'min_child_samples': 52, 'subsample': 0.8268191955371778, 'colsample_bytree': 0.6009521013247232, 'reg_alpha': 0.18972434744669014, 'reg_lambda': 0.5158300771050285}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:24,842] Trial 17 finished with value: 0.6723404255319149 and parameters: {'n_estimators': 1179, 'num_leaves': 75, 'learning_rate': 0.022648684370767082, 'max_depth': 15, 'min_child_samples': 22, 'subsample': 0.8919306048028114, 'colsample_bytree': 0.6684552834736661, 'reg_alpha': 0.4387550856892768, 'reg_lambda': 0.8817927574670874}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:25,354] Trial 18 finished with value: 0.679324894514768 and parameters: {'n_estimators': 682, 'num_leaves': 124, 'learning_rate': 0.03788899123949597, 'max_depth': 10, 'min_child_samples': 51, 'subsample': 0.750345511862074, 'colsample_bytree': 0.766758921551695, 'reg_alpha': 0.6726655631256198, 'reg_lambda': 0.7204857755469992}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:26,329] Trial 19 finished with value: 0.6652267818574514 and parameters: {'n_estimators': 882, 'num_leaves': 45, 'learning_rate': 0.05195867097315689, 'max_depth': 12, 'min_child_samples': 26, 'subsample': 0.9862151473295395, 'colsample_bytree': 0.6850153145156537, 'reg_alpha': 0.002223364194784083, 'reg_lambda': 0.8991583583360986}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:26,769] Trial 20 finished with value: 0.679324894514768 and parameters: {'n_estimators': 553, 'num_leaves': 102, 'learning_rate': 0.07803517664691265, 'max_depth': 8, 'min_child_samples': 37, 'subsample': 0.8795600615577324, 'colsample_bytree': 0.8587882430180515, 'reg_alpha': 0.21118265431609795, 'reg_lambda': 0.999155098184834}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:27,381] Trial 21 finished with value: 0.6808510638297872 and parameters: {'n_estimators': 485, 'num_leaves': 31, 'learning_rate': 0.034280729757230524, 'max_depth': 15, 'min_child_samples': 46, 'subsample': 0.6053594441258244, 'colsample_bytree': 0.6019066463817481, 'reg_alpha': 0.35460063788302987, 'reg_lambda': 0.7803078115982535}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:27,825] Trial 22 finished with value: 0.6932773109243697 and parameters: {'n_estimators': 480, 'num_leaves': 65, 'learning_rate': 0.018962980026769855, 'max_depth': 14, 'min_child_samples': 49, 'subsample': 0.6443714365658868, 'colsample_bytree': 0.6422797134907883, 'reg_alpha': 0.2944625677052787, 'reg_lambda': 0.8793328197848147}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:28,195] Trial 23 finished with value: 0.6923076923076923 and parameters: {'n_estimators': 448, 'num_leaves': 68, 'learning_rate': 0.0205976632118514, 'max_depth': 13, 'min_child_samples': 57, 'subsample': 0.6489565793409156, 'colsample_bytree': 0.6446941575096728, 'reg_alpha': 0.44031136964797274, 'reg_lambda': 0.8837729831296919}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:29,079] Trial 24 finished with value: 0.6997840172786177 and parameters: {'n_estimators': 1034, 'num_leaves': 83, 'learning_rate': 0.018611981793624603, 'max_depth': 14, 'min_child_samples': 49, 'subsample': 0.6508239678341097, 'colsample_bytree': 0.7008845119019989, 'reg_alpha': 0.21780485207300535, 'reg_lambda': 0.5835927313251472}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:29,993] Trial 25 finished with value: 0.6824034334763949 and parameters: {'n_estimators': 1031, 'num_leaves': 84, 'learning_rate': 0.01843499674184393, 'max_depth': 14, 'min_child_samples': 48, 'subsample': 0.7145716612706464, 'colsample_bytree': 0.6927502418164438, 'reg_alpha': 0.12281340889768677, 'reg_lambda': 0.3865470531565245}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:30,994] Trial 26 finished with value: 0.6809421841541756 and parameters: {'n_estimators': 1045, 'num_leaves': 76, 'learning_rate': 0.030841227675773714, 'max_depth': 14, 'min_child_samples': 39, 'subsample': 0.808556791550679, 'colsample_bytree': 0.7797068039597577, 'reg_alpha': 0.40166606250793635, 'reg_lambda': 0.574924007657438}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:31,891] Trial 27 finished with value: 0.6752688172043011 and parameters: {'n_estimators': 1188, 'num_leaves': 95, 'learning_rate': 0.0439158700754041, 'max_depth': 11, 'min_child_samples': 34, 'subsample': 0.6451948668352327, 'colsample_bytree': 0.7050977559187958, 'reg_alpha': 0.5000369312895585, 'reg_lambda': 0.4151475596898355}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:32,725] Trial 28 finished with value: 0.6952789699570815 and parameters: {'n_estimators': 916, 'num_leaves': 58, 'learning_rate': 0.01639284931494192, 'max_depth': 12, 'min_child_samples': 41, 'subsample': 0.71486217555981, 'colsample_bytree': 0.7493319719341608, 'reg_alpha': 0.147892746031487, 'reg_lambda': 0.7132190284265154}. Best is trial 5 with value: 0.7016806722689075.\n",
      "[I 2025-10-24 12:49:33,552] Trial 29 finished with value: 0.693446088794926 and parameters: {'n_estimators': 894, 'num_leaves': 49, 'learning_rate': 0.011689215528626624, 'max_depth': 12, 'min_child_samples': 41, 'subsample': 0.7005113107250712, 'colsample_bytree': 0.794127509581841, 'reg_alpha': 0.8797700812352318, 'reg_lambda': 0.2475920111641709}. Best is trial 5 with value: 0.7016806722689075.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 921, 'num_leaves': 101, 'learning_rate': 0.023900521549360454, 'max_depth': 8, 'min_child_samples': 28, 'subsample': 0.8966084715813978, 'colsample_bytree': 0.8275400285591212, 'reg_alpha': 0.4884094828732616, 'reg_lambda': 0.9498436227759033}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "def objective(trial):\n",
    "    params = dict(\n",
    "        n_estimators=trial.suggest_int('n_estimators', 400, 1200),\n",
    "        num_leaves=trial.suggest_int('num_leaves', 31, 127),\n",
    "        learning_rate=trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        max_depth=trial.suggest_int('max_depth', 5, 15),\n",
    "        min_child_samples=trial.suggest_int('min_child_samples', 10, 60),\n",
    "        subsample=trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        colsample_bytree=trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        reg_alpha=trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        reg_lambda=trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        random_state=42,\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(X_train_sel, y_train)\n",
    "    preds = model.predict(X_test_sel)\n",
    "    return f1_score(y_test, preds)\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "print(study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77907694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fcc93fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = {\n",
    "    'aromatic': Chem.MolFromSmarts('a'),\n",
    "    'amine': Chem.MolFromSmarts('[NX3;H2,H1;!$(NC=O)]'),\n",
    "    'carboxyl': Chem.MolFromSmarts('C(=O)[OH]'),\n",
    "}\n",
    "for name, patt in patterns.items():\n",
    "    df[name] = df[smiles_col].apply(lambda s: int(Chem.MolFromSmiles(s).HasSubstructMatch(patt)) if Chem.MolFromSmiles(s) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f26d335e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, learning_rate=0.05, max_depth=5,\n",
       "               n_estimators=300, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves&nbsp;</td>\n",
       "            <td class=\"value\">31</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.05</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin&nbsp;</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples&nbsp;</td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', learning_rate=0.05, max_depth=5,\n",
       "               n_estimators=300, random_state=42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = lgb.LGBMClassifier(\n",
    "    n_estimators=300, learning_rate=0.05, max_depth=5,\n",
    "    random_state=42, class_weight='balanced'\n",
    ")\n",
    "meta.fit(oof_preds, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d793254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACKED ROC-AUC: 0.7499208721645859\n",
      "STACKED Acc: 0.6729559748427673\n",
      "STACKED Best F1: 0.7142857142857143 Thr: 0.40108969684749196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.52      0.62       242\n",
      "           1       0.63      0.83      0.71       235\n",
      "\n",
      "    accuracy                           0.67       477\n",
      "   macro avg       0.69      0.68      0.67       477\n",
      "weighted avg       0.69      0.67      0.67       477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------- Train meta LightGBM (using tuned parameters) ----------\n",
    "meta_params = dict(\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=31,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=300,\n",
    "    subsample_for_bin=200000,\n",
    "    class_weight='balanced',\n",
    "    min_split_gain=0.0,\n",
    "    min_child_weight=0.001,\n",
    "    min_child_samples=20,\n",
    "    subsample=1.0,\n",
    "    subsample_freq=0,\n",
    "    colsample_bytree=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    random_state=42,\n",
    "    importance_type='split'\n",
    ")\n",
    "\n",
    "meta = lgb.LGBMClassifier(**meta_params)\n",
    "meta.fit(oof_preds, y_train)\n",
    "\n",
    "meta_test_preds = meta.predict_proba(test_preds)[:, 1]\n",
    "\n",
    "# threshold optimization\n",
    "p, r, th = precision_recall_curve(y_test, meta_test_preds)\n",
    "f1s = 2 * p * r / (p + r + 1e-12)\n",
    "best_thr = float(th[np.nanargmax(f1s)]) if len(th) > 0 else 0.5\n",
    "y_pred = (meta_test_preds >= best_thr).astype(int)\n",
    "\n",
    "print(\"STACKED ROC-AUC:\", roc_auc_score(y_test, meta_test_preds))\n",
    "print(\"STACKED Acc:\", accuracy_score(y_test, y_pred))\n",
    "print(\"STACKED Best F1:\", f1_score(y_test, y_pred), \"Thr:\", best_thr)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d8dd5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FP gen: 100%|██████████| 2384/2384 [00:01<00:00, 1463.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating OOF for cat\n",
      "Generating OOF for xgb\n",
      "Generating OOF for lgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:27,924] A new study created in memory with name: no-name-d8c3b058-4213-44c4-a339-b824e44b53e7\n",
      "Best trial: 0. Best value: 0.667127:   3%|▎         | 1/30 [00:00<00:06,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:28,154] Trial 0 finished with value: 0.6671271637735329 and parameters: {'num_leaves': 63, 'max_depth': 10, 'learning_rate': 0.060030378006659, 'n_estimators': 113, 'subsample': 0.9277067535118697, 'colsample_bytree': 0.8453957410293524, 'reg_alpha': 0.5508860958377484, 'reg_lambda': 0.970875566478768}. Best is trial 0 with value: 0.6671271637735329.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.677755:   7%|▋         | 2/30 [00:00<00:06,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:28,392] Trial 1 finished with value: 0.6777551169490241 and parameters: {'num_leaves': 125, 'max_depth': 7, 'learning_rate': 0.0530595392975674, 'n_estimators': 161, 'subsample': 0.601111600758949, 'colsample_bytree': 0.6608000304226832, 'reg_alpha': 0.10497714550340609, 'reg_lambda': 0.631049520443672}. Best is trial 1 with value: 0.6777551169490241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.678085:  10%|█         | 3/30 [00:00<00:06,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:28,601] Trial 2 finished with value: 0.6780846545501011 and parameters: {'num_leaves': 59, 'max_depth': 3, 'learning_rate': 0.09099578120765804, 'n_estimators': 328, 'subsample': 0.8525866226181606, 'colsample_bytree': 0.7628526359121064, 'reg_alpha': 0.30065613051305473, 'reg_lambda': 0.8801953346808753}. Best is trial 2 with value: 0.6780846545501011.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.678085:  13%|█▎        | 4/30 [00:01<00:09,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:29,161] Trial 3 finished with value: 0.6442486987023932 and parameters: {'num_leaves': 23, 'max_depth': 7, 'learning_rate': 0.09987183078126885, 'n_estimators': 490, 'subsample': 0.6250412842187179, 'colsample_bytree': 0.7247259576093367, 'reg_alpha': 0.18739293085040865, 'reg_lambda': 0.7617730416782523}. Best is trial 2 with value: 0.6780846545501011.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.693115:  17%|█▋        | 5/30 [00:01<00:08,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:29,446] Trial 4 finished with value: 0.6691390260155303 and parameters: {'num_leaves': 93, 'max_depth': 4, 'learning_rate': 0.05465746455653373, 'n_estimators': 346, 'subsample': 0.7424671917684628, 'colsample_bytree': 0.9451577612286506, 'reg_alpha': 0.02061525812630416, 'reg_lambda': 0.6861103182524741}. Best is trial 2 with value: 0.6780846545501011.\n",
      "[I 2025-10-24 12:54:29,535] Trial 5 finished with value: 0.6931154836412771 and parameters: {'num_leaves': 115, 'max_depth': 3, 'learning_rate': 0.09658781068320088, 'n_estimators': 115, 'subsample': 0.6620026893049974, 'colsample_bytree': 0.6257384916722559, 'reg_alpha': 0.015062510690484032, 'reg_lambda': 0.45738001395885697}. Best is trial 5 with value: 0.6931154836412771.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.693115:  23%|██▎       | 7/30 [00:02<00:07,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:30,013] Trial 6 finished with value: 0.6556274376708887 and parameters: {'num_leaves': 60, 'max_depth': 6, 'learning_rate': 0.08990015613590814, 'n_estimators': 444, 'subsample': 0.7470588079228418, 'colsample_bytree': 0.7393759785333448, 'reg_alpha': 0.4702715824408805, 'reg_lambda': 0.35251601411490696}. Best is trial 5 with value: 0.6931154836412771.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.693115:  27%|██▋       | 8/30 [00:02<00:07,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:30,441] Trial 7 finished with value: 0.6539231592816799 and parameters: {'num_leaves': 68, 'max_depth': 9, 'learning_rate': 0.06239618571583482, 'n_estimators': 262, 'subsample': 0.6679371346232449, 'colsample_bytree': 0.9333879883903694, 'reg_alpha': 0.5687737508135392, 'reg_lambda': 0.7051524924543804}. Best is trial 5 with value: 0.6931154836412771.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.693115:  30%|███       | 9/30 [00:02<00:06,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:30,716] Trial 8 finished with value: 0.6844424325674325 and parameters: {'num_leaves': 19, 'max_depth': 5, 'learning_rate': 0.03917036235888853, 'n_estimators': 266, 'subsample': 0.8578570428744211, 'colsample_bytree': 0.6837337607534074, 'reg_alpha': 0.9706591162610798, 'reg_lambda': 0.14637048518699303}. Best is trial 5 with value: 0.6931154836412771.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.703336:  37%|███▋      | 11/30 [00:03<00:04,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:30,934] Trial 9 finished with value: 0.681950855300179 and parameters: {'num_leaves': 55, 'max_depth': 8, 'learning_rate': 0.0562160919486785, 'n_estimators': 128, 'subsample': 0.8195709361309909, 'colsample_bytree': 0.7953224536900015, 'reg_alpha': 0.21838309963003855, 'reg_lambda': 0.3036475476908024}. Best is trial 5 with value: 0.6931154836412771.\n",
      "[I 2025-10-24 12:54:31,091] Trial 10 finished with value: 0.7033362853133767 and parameters: {'num_leaves': 127, 'max_depth': 3, 'learning_rate': 0.01638317693084742, 'n_estimators': 208, 'subsample': 0.7110052811517344, 'colsample_bytree': 0.6157025804399965, 'reg_alpha': 0.8610919403245393, 'reg_lambda': 0.013975813886521693}. Best is trial 10 with value: 0.7033362853133767.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  40%|████      | 12/30 [00:03<00:04,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:31,242] Trial 11 finished with value: 0.7061890686648017 and parameters: {'num_leaves': 125, 'max_depth': 3, 'learning_rate': 0.014782075499239676, 'n_estimators': 209, 'subsample': 0.7055468678072342, 'colsample_bytree': 0.6066890126169595, 'reg_alpha': 0.8749394784390284, 'reg_lambda': 0.0076835312688198765}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  47%|████▋     | 14/30 [00:03<00:03,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:31,493] Trial 12 finished with value: 0.6936946420000581 and parameters: {'num_leaves': 103, 'max_depth': 5, 'learning_rate': 0.012845188489863801, 'n_estimators': 215, 'subsample': 0.7372487579472237, 'colsample_bytree': 0.6109801070052369, 'reg_alpha': 0.9262202955200654, 'reg_lambda': 0.0016807499630800728}. Best is trial 11 with value: 0.7061890686648017.\n",
      "[I 2025-10-24 12:54:31,641] Trial 13 finished with value: 0.7031988128592095 and parameters: {'num_leaves': 128, 'max_depth': 3, 'learning_rate': 0.015905525266096215, 'n_estimators': 201, 'subsample': 0.704784162418893, 'colsample_bytree': 0.610835462413989, 'reg_alpha': 0.7940636646717698, 'reg_lambda': 0.020305310110046697}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  50%|█████     | 15/30 [00:03<00:02,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:31,821] Trial 14 finished with value: 0.7022300837546488 and parameters: {'num_leaves': 89, 'max_depth': 4, 'learning_rate': 0.028775290706354067, 'n_estimators': 204, 'subsample': 0.7863138721309075, 'colsample_bytree': 0.6816315271683072, 'reg_alpha': 0.7622022914908223, 'reg_lambda': 0.2222646399556423}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  53%|█████▎    | 16/30 [00:04<00:03,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:32,207] Trial 15 finished with value: 0.6791292045373258 and parameters: {'num_leaves': 111, 'max_depth': 5, 'learning_rate': 0.0274127895143476, 'n_estimators': 369, 'subsample': 0.9805925394879635, 'colsample_bytree': 0.8670962352336871, 'reg_alpha': 0.7436002841335362, 'reg_lambda': 0.14058100995170167}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  57%|█████▋    | 17/30 [00:04<00:03,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:32,417] Trial 16 finished with value: 0.7061363824745026 and parameters: {'num_leaves': 87, 'max_depth': 4, 'learning_rate': 0.026421826295884722, 'n_estimators': 255, 'subsample': 0.6886469671698864, 'colsample_bytree': 0.6591530061082425, 'reg_alpha': 0.8633287281827223, 'reg_lambda': 0.45109695614305334}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  60%|██████    | 18/30 [00:04<00:02,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:32,652] Trial 17 finished with value: 0.6956364464389762 and parameters: {'num_leaves': 85, 'max_depth': 4, 'learning_rate': 0.03987820013414933, 'n_estimators': 280, 'subsample': 0.6605585902029949, 'colsample_bytree': 0.6969897864315031, 'reg_alpha': 0.6987394645817688, 'reg_lambda': 0.5013428209392776}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  63%|██████▎   | 19/30 [00:05<00:03,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:33,125] Trial 18 finished with value: 0.6716162506615053 and parameters: {'num_leaves': 39, 'max_depth': 6, 'learning_rate': 0.02507299142891564, 'n_estimators': 394, 'subsample': 0.7809903544326013, 'colsample_bytree': 0.9960008580541837, 'reg_alpha': 0.6220440169034813, 'reg_lambda': 0.5255903963051161}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  67%|██████▋   | 20/30 [00:05<00:02,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:33,384] Trial 19 finished with value: 0.6879261145144173 and parameters: {'num_leaves': 77, 'max_depth': 4, 'learning_rate': 0.03863299165810515, 'n_estimators': 303, 'subsample': 0.6889579740981933, 'colsample_bytree': 0.6590763042167581, 'reg_alpha': 0.3535158022736944, 'reg_lambda': 0.3983879261007064}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  73%|███████▎  | 22/30 [00:05<00:01,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:33,651] Trial 20 finished with value: 0.6933045259837634 and parameters: {'num_leaves': 101, 'max_depth': 5, 'learning_rate': 0.022079191598911505, 'n_estimators': 241, 'subsample': 0.62759923785566, 'colsample_bytree': 0.7934873170628445, 'reg_alpha': 0.9758751543925505, 'reg_lambda': 0.23772860277379407}. Best is trial 11 with value: 0.7061890686648017.\n",
      "[I 2025-10-24 12:54:33,786] Trial 21 finished with value: 0.7047520586383657 and parameters: {'num_leaves': 118, 'max_depth': 3, 'learning_rate': 0.011118095493641093, 'n_estimators': 170, 'subsample': 0.7126048695190536, 'colsample_bytree': 0.632408952254492, 'reg_alpha': 0.8695545259583017, 'reg_lambda': 0.0834402566367442}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  80%|████████  | 24/30 [00:06<00:01,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:33,914] Trial 22 finished with value: 0.7058095455972083 and parameters: {'num_leaves': 115, 'max_depth': 3, 'learning_rate': 0.012986873522143177, 'n_estimators': 159, 'subsample': 0.7191633136936476, 'colsample_bytree': 0.6528010232182708, 'reg_alpha': 0.8732620141725991, 'reg_lambda': 0.13434779243607148}. Best is trial 11 with value: 0.7061890686648017.\n",
      "[I 2025-10-24 12:54:34,074] Trial 23 finished with value: 0.7027321703763878 and parameters: {'num_leaves': 106, 'max_depth': 4, 'learning_rate': 0.034020776615492875, 'n_estimators': 162, 'subsample': 0.7611936527220422, 'colsample_bytree': 0.7081214858966277, 'reg_alpha': 0.848471886138627, 'reg_lambda': 0.2355775711645381}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  87%|████████▋ | 26/30 [00:06<00:00,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:34,237] Trial 24 finished with value: 0.6843886557051688 and parameters: {'num_leaves': 79, 'max_depth': 3, 'learning_rate': 0.07297516767499262, 'n_estimators': 234, 'subsample': 0.8074931145251049, 'colsample_bytree': 0.6533599636705065, 'reg_alpha': 0.6822969000205413, 'reg_lambda': 0.14964905266161246}. Best is trial 11 with value: 0.7061890686648017.\n",
      "[I 2025-10-24 12:54:34,396] Trial 25 finished with value: 0.6973937011759042 and parameters: {'num_leaves': 98, 'max_depth': 4, 'learning_rate': 0.020476174224369842, 'n_estimators': 175, 'subsample': 0.6830114695378909, 'colsample_bytree': 0.7571633448894973, 'reg_alpha': 0.9022230733156916, 'reg_lambda': 0.10158124078711989}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  90%|█████████ | 27/30 [00:06<00:00,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:34,595] Trial 26 finished with value: 0.6909065846231027 and parameters: {'num_leaves': 117, 'max_depth': 6, 'learning_rate': 0.046720212177877044, 'n_estimators': 151, 'subsample': 0.6342355237036269, 'colsample_bytree': 0.6732313975546399, 'reg_alpha': 0.441370644639712, 'reg_lambda': 0.5703548101928494}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  93%|█████████▎| 28/30 [00:06<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:34,811] Trial 27 finished with value: 0.6967839368902577 and parameters: {'num_leaves': 110, 'max_depth': 3, 'learning_rate': 0.032562406625657424, 'n_estimators': 322, 'subsample': 0.720855439650965, 'colsample_bytree': 0.646133938269442, 'reg_alpha': 0.6490664791560786, 'reg_lambda': 0.3225506267089189}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189:  97%|█████████▋| 29/30 [00:07<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:35,096] Trial 28 finished with value: 0.691612994113483 and parameters: {'num_leaves': 120, 'max_depth': 5, 'learning_rate': 0.019205973656453677, 'n_estimators': 246, 'subsample': 0.84214184905959, 'colsample_bytree': 0.8473058663309462, 'reg_alpha': 0.9964131052106414, 'reg_lambda': 0.4203213656723008}. Best is trial 11 with value: 0.7061890686648017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.706189: 100%|██████████| 30/30 [00:07<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 12:54:35,685] Trial 29 finished with value: 0.6878288360244696 and parameters: {'num_leaves': 93, 'max_depth': 9, 'learning_rate': 0.010894683682087678, 'n_estimators': 292, 'subsample': 0.9005891538290005, 'colsample_bytree': 0.6043358070185421, 'reg_alpha': 0.783876496024531, 'reg_lambda': 0.8848946948987655}. Best is trial 11 with value: 0.7061890686648017.\n",
      "Best meta params: {'num_leaves': 125, 'max_depth': 3, 'learning_rate': 0.014782075499239676, 'n_estimators': 209, 'subsample': 0.7055468678072342, 'colsample_bytree': 0.6066890126169595, 'reg_alpha': 0.8749394784390284, 'reg_lambda': 0.0076835312688198765}\n",
      "STACKED ROC-AUC: 0.7658519430279586\n",
      "STACKED Acc: 0.6289308176100629\n",
      "STACKED Best F1: 0.721259842519685 Thr: 0.19670022481362104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.29      0.45       242\n",
      "           1       0.57      0.97      0.72       235\n",
      "\n",
      "    accuracy                           0.63       477\n",
      "   macro avg       0.75      0.63      0.58       477\n",
      "weighted avg       0.75      0.63      0.58       477\n",
      "\n",
      "Saved -> best_ensemble_final_v3.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# upgraded_pipeline_v3.py\n",
    "# Requires: rdkit, optuna, lightgbm, xgboost, catboost, sklearn, joblib, pandas, numpy, tqdm\n",
    "\n",
    "import warnings, joblib, optuna\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.rdMolDescriptors import CalcTPSA\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.base import clone\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# ---------- config ----------\n",
    "PATH = \"reference_database(Hepato).xlsx\"\n",
    "SMILES_COL_HINT = 'smile'\n",
    "LABEL_HINTS = ['label','final','tox','dili','pos','neg']\n",
    "FP_SIZE = 1024\n",
    "R2, R3 = 2, 3\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS = 5\n",
    "N_REPEATS = 2  # repeated CV for stability\n",
    "OPTUNA_TRIALS = 30  # tune meta\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def mol_from_smiles_safe(s):\n",
    "    try: return Chem.MolFromSmiles(str(s))\n",
    "    except: return None\n",
    "\n",
    "def rdkit_core(m):\n",
    "    return {\n",
    "        \"ExactMolWt\": float(Descriptors.ExactMolWt(m)),\n",
    "        \"MolLogP\": float(Descriptors.MolLogP(m)),\n",
    "        \"TPSA\": float(CalcTPSA(m)),\n",
    "        \"NumHDonors\": int(Descriptors.NumHDonors(m)),\n",
    "        \"NumHAcceptors\": int(Descriptors.NumHAcceptors(m)),\n",
    "        \"NumRotatableBonds\": int(Descriptors.NumRotatableBonds(m)),\n",
    "        \"HeavyAtomCount\": int(m.GetNumHeavyAtoms()),\n",
    "        \"FracCSP3\": float(Descriptors.FractionCSP3(m)),\n",
    "        \"RingCount\": int(Descriptors.RingCount(m)) if hasattr(Descriptors,'RingCount') else 0,\n",
    "        \"AromaticRings\": int(len([r for r in m.GetRingInfo().AtomRings() if any(m.GetAtomWithIdx(i).GetIsAromatic() for i in r)]))\n",
    "    }\n",
    "\n",
    "# SMARTS patterns (binary flags)\n",
    "SMARTS = {\n",
    "    \"has_amine\": \"[NX3;!$(NC=O)]\",\n",
    "    \"has_carboxyl\": \"C(=O)[OX2H1]\",\n",
    "    \"has_nitro\": \"[NX3](=O)=O\",\n",
    "    \"has_halogen\": \"[F,Cl,Br,I]\",\n",
    "    \"has_aromatic\": \"a\"\n",
    "}\n",
    "SMARTS_PATTS = {k: Chem.MolFromSmarts(v) for k,v in SMARTS.items()}\n",
    "\n",
    "# ---------- load ----------\n",
    "df = pd.read_excel(PATH, sheet_name=0)\n",
    "smiles_col = next((c for c in df.columns if SMILES_COL_HINT in str(c).lower()), None)\n",
    "label_col = next((c for c in df.columns if any(x in str(c).lower() for x in LABEL_HINTS)), None)\n",
    "if smiles_col is None or label_col is None: raise RuntimeError(\"Can't detect SMILES/label columns.\")\n",
    "df = df.dropna(subset=[smiles_col, label_col]).reset_index(drop=True)\n",
    "\n",
    "# label mapping\n",
    "def map_label(v):\n",
    "    s = str(v).strip().lower()\n",
    "    if any(x in s for x in ['pos','p','yes','y','true','t']): return 1\n",
    "    if any(x in s for x in ['neg','n','no','false','f','-1']): return 0\n",
    "    try: return 1 if float(s)>0 else 0\n",
    "    except: return None\n",
    "df['label'] = df[label_col].apply(map_label)\n",
    "df = df.dropna(subset=['label']).reset_index(drop=True)\n",
    "df['label']=df['label'].astype(int)\n",
    "\n",
    "# ---------- features: fingerprints, rdkit descs, SMARTS -------\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "m2 = GetMorganGenerator(radius=R2, fpSize=FP_SIZE, countSimulation=True)\n",
    "m3 = GetMorganGenerator(radius=R3, fpSize=FP_SIZE, countSimulation=True)\n",
    "\n",
    "fps=[]; descs=[]; smarts_rows=[]; valid=[]\n",
    "for s in tqdm(df[smiles_col].astype(str), desc=\"FP gen\"):\n",
    "    m = mol_from_smiles_safe(s)\n",
    "    if m is None:\n",
    "        valid.append(False); fps.append(np.zeros(FP_SIZE*2,dtype=int)); descs.append({}); smarts_rows.append({})\n",
    "        continue\n",
    "    valid.append(True)\n",
    "    a2=np.zeros((FP_SIZE,),dtype=int); DataStructs=Chem.DataStructs\n",
    "    DataStructs.ConvertToNumpyArray(m2.GetFingerprint(m), a2)\n",
    "    a3=np.zeros((FP_SIZE,),dtype=int); DataStructs.ConvertToNumpyArray(m3.GetFingerprint(m), a3)\n",
    "    fps.append(np.hstack([a2,a3]))\n",
    "    rd = rdkit_core(m)\n",
    "    # interactions\n",
    "    rd['LogP_over_MW'] = rd['MolLogP']/(rd['ExactMolWt']+1e-9)\n",
    "    rd['TPSA_per_Heavy'] = rd['TPSA']/(rd['HeavyAtomCount']+1e-9)\n",
    "    descs.append(rd)\n",
    "    # SMARTS flags\n",
    "    flags = {k:int(m.HasSubstructMatch(p)) for k,p in SMARTS_PATTS.items()}\n",
    "    smarts_rows.append(flags)\n",
    "\n",
    "desc_df = pd.DataFrame(descs).fillna(np.nan).reset_index(drop=True)\n",
    "smarts_df = pd.DataFrame(smarts_rows).fillna(0).astype(int).reset_index(drop=True)\n",
    "FP = np.vstack(fps).astype(float)\n",
    "# clip LogP extremes\n",
    "if 'MolLogP' in desc_df.columns: desc_df['MolLogP']=desc_df['MolLogP'].clip(-10,10)\n",
    "\n",
    "# scale descriptors\n",
    "desc_scale_cols = desc_df.columns.tolist()\n",
    "scaler = RobustScaler()\n",
    "desc_scaled = pd.DataFrame(scaler.fit_transform(desc_df.fillna(0)), columns=[c+\"_s\" for c in desc_scale_cols])\n",
    "\n",
    "# build final X\n",
    "X = np.hstack([FP, desc_scaled.values, smarts_df.values])\n",
    "y = df['label'].values\n",
    "\n",
    "# ---------- train/test split ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=RANDOM_STATE,stratify=y)\n",
    "\n",
    "# ---------- initial LightGBM for importance -> top25% ----------\n",
    "lgb_base = lgb.LGBMClassifier(n_estimators=800, learning_rate=0.03, random_state=RANDOM_STATE, class_weight='balanced')\n",
    "lgb_base.fit(X_train, y_train, eval_set=[(X_test,y_test)], eval_metric='binary_logloss',\n",
    "             callbacks=[lgb.early_stopping(stopping_rounds=60), lgb.log_evaluation(period=0)])\n",
    "imp = lgb_base.feature_importances_\n",
    "th = np.percentile(imp, 75)  # top 25%\n",
    "sel = SelectFromModel(lgb_base, threshold=th, prefit=True)\n",
    "X_train_sel = sel.transform(X_train); X_test_sel = sel.transform(X_test)\n",
    "\n",
    "# ---------- base models (train on selected features) ----------\n",
    "cat = CatBoostClassifier(iterations=800, learning_rate=0.03, depth=6, random_seed=RANDOM_STATE, verbose=0, class_weights=[1.0,1.0])\n",
    "xg = xgb.XGBClassifier(n_estimators=600, learning_rate=0.03, max_depth=8, use_label_encoder=False, eval_metric='logloss')\n",
    "lgbf = lgb.LGBMClassifier(n_estimators=800, learning_rate=0.03, random_state=RANDOM_STATE)\n",
    "\n",
    "# ---------- stacking with repeated stratified KFold (stabilize OOF) ----------\n",
    "rkf = RepeatedStratifiedKFold(n_splits=N_SPLITS, n_repeats=N_REPEATS, random_state=RANDOM_STATE)\n",
    "oof = np.zeros((X_train_sel.shape[0], 3))\n",
    "test_preds = np.zeros((X_test_sel.shape[0], 3))\n",
    "\n",
    "for i,(name,est) in enumerate([('cat',cat),('xgb',xg),('lgb',lgbf)]):\n",
    "    print(\"Generating OOF for\", name)\n",
    "    fold_preds = np.zeros((X_test_sel.shape[0], N_SPLITS * N_REPEATS))\n",
    "    o = np.zeros(X_train_sel.shape[0])\n",
    "    fold_idx = 0\n",
    "    for train_idx, val_idx in rkf.split(X_train_sel, y_train):\n",
    "        X_tr, X_val = X_train_sel[train_idx], X_train_sel[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        e = clone(est)\n",
    "        if name=='lgb':\n",
    "            e.fit(X_tr, y_tr, eval_set=[(X_val,y_val)], eval_metric='binary_logloss',\n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=40), lgb.log_evaluation(period=0)])\n",
    "        elif name=='cat':\n",
    "            e.fit(X_tr, y_tr, eval_set=(X_val,y_val), verbose=0)\n",
    "        else:\n",
    "            e.fit(X_tr, y_tr)\n",
    "        o[val_idx] = e.predict_proba(X_val)[:,1]\n",
    "        fold_preds[:, fold_idx] = e.predict_proba(X_test_sel)[:,1]\n",
    "        fold_idx += 1\n",
    "    oof[:, i] = o\n",
    "    test_preds[:, i] = fold_preds.mean(axis=1)\n",
    "\n",
    "# ---------- Optuna: tune meta LightGBM on OOF -> maximize CV F1 ----------\n",
    "def optuna_objective(trial):\n",
    "    p = dict(\n",
    "        num_leaves=trial.suggest_int(\"num_leaves\", 16, 128),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        reg_alpha=trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "        reg_lambda=trial.suggest_float(\"reg_lambda\", 0.0, 1.0),\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    f1s = []\n",
    "    for tr, val in cv.split(oof, y_train):\n",
    "        m = lgb.LGBMClassifier(**p)\n",
    "        m.fit(oof[tr], y_train[tr])\n",
    "        pred = (m.predict_proba(oof[val])[:,1] >= 0.5).astype(int)\n",
    "        f1s.append(f1_score(y_train[val], pred))\n",
    "    return np.mean(f1s)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(optuna_objective, n_trials=OPTUNA_TRIALS, show_progress_bar=True)\n",
    "best_meta_params = study.best_params\n",
    "print(\"Best meta params:\", best_meta_params)\n",
    "\n",
    "# ---------- train meta with best params ----------\n",
    "meta = lgb.LGBMClassifier(**best_meta_params)\n",
    "meta.fit(oof, y_train)\n",
    "meta_test_preds = meta.predict_proba(test_preds)[:,1]\n",
    "\n",
    "# ---------- threshold tuning on test preds using PR-curve (best F1) ----------\n",
    "p, r, th = precision_recall_curve(y_test, meta_test_preds)\n",
    "f1s = 2*p*r/(p+r+1e-12)\n",
    "best_thr = float(th[np.nanargmax(f1s)]) if len(th)>0 else 0.5\n",
    "y_pred = (meta_test_preds >= best_thr).astype(int)\n",
    "\n",
    "print(\"STACKED ROC-AUC:\", roc_auc_score(y_test, meta_test_preds))\n",
    "print(\"STACKED Acc:\", accuracy_score(y_test, y_pred))\n",
    "print(\"STACKED Best F1:\", f1_score(y_test, y_pred), \"Thr:\", best_thr)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ---------- save artifact ----------\n",
    "artifact = {\n",
    "    'selector': sel,\n",
    "    'scaler': scaler,\n",
    "    'smart_patterns': SMARTS,\n",
    "    'base_models': {'cat': cat, 'xgb': xg, 'lgb': lgbf},\n",
    "    'meta': meta,\n",
    "    'best_meta_params': best_meta_params,\n",
    "    'threshold': best_thr\n",
    "}\n",
    "joblib.dump(artifact, \"best_ensemble_final_v3.pkl\")\n",
    "print(\"Saved -> best_ensemble_final_v3.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68b4f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[smiles_col] = (\n",
    "    df[smiles_col]\n",
    "    .astype(str)\n",
    "    .str.strip()        # remove spaces\n",
    "    .str.replace(r'[^A-Za-z0-9@+\\-\\[\\]\\(\\)=#\\\\/]', '', regex=True)  # remove illegal chars\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "929f262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 2384 rows.\n",
      "Detected SMILES column: SMILES\n",
      "✅ Parsed 2384 valid molecules out of 2384 total.\n",
      "\n",
      "✅ Descriptors successfully computed and saved!\n",
      "Saved → reference_database(Hepato)_with_descs_fixed.xlsx\n",
      "Final rows: 2384 (only valid molecules retained)\n"
     ]
    }
   ],
   "source": [
    "# compute_clean_rdkit_descriptors_fixed.py\n",
    "# ✅ Cleans SMILES, computes all valid molecular descriptors, removes invalid rows\n",
    "# ✅ Saves updated Excel as reference_database(Hepato)_with_descs_fixed.xlsx\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.rdMolDescriptors import CalcTPSA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# -------------------- Paths --------------------\n",
    "INPUT_PATH  = \"reference_database(Hepato).xlsx\"\n",
    "OUTPUT_PATH = \"reference_database(Hepato)_with_descs_fixed.xlsx\"\n",
    "\n",
    "# -------------------- Load dataset --------------------\n",
    "df = pd.read_excel(INPUT_PATH)\n",
    "print(f\"Loaded dataset with {len(df)} rows.\")\n",
    "\n",
    "# Auto-detect SMILES column\n",
    "smiles_col = next((c for c in df.columns if 'smile' in str(c).lower()), None)\n",
    "if smiles_col is None:\n",
    "    raise RuntimeError(\"❌ Couldn't find a SMILES-like column. Rename one column to include 'smile'.\")\n",
    "\n",
    "print(f\"Detected SMILES column: {smiles_col}\")\n",
    "\n",
    "# -------------------- Clean SMILES strings --------------------\n",
    "df[smiles_col] = (\n",
    "    df[smiles_col]\n",
    "    .astype(str)\n",
    "    .str.strip()                                  # remove extra spaces\n",
    "    .str.replace(r'[^A-Za-z0-9@+\\-\\[\\]\\(\\)=#\\\\/]', '', regex=True)  # clean illegal chars\n",
    "    .str.replace(' ', '', regex=False)            # remove spaces\n",
    ")\n",
    "\n",
    "# -------------------- Helper functions --------------------\n",
    "def mol_from_smiles_safe(s):\n",
    "    \"\"\"Safely convert SMILES to RDKit Mol, returns None if invalid.\"\"\"\n",
    "    try:\n",
    "        m = Chem.MolFromSmiles(s)\n",
    "        if m is None:\n",
    "            return None\n",
    "        Chem.SanitizeMol(m)\n",
    "        return m\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def compute_rdkit_descs(mol):\n",
    "    \"\"\"Compute core molecular descriptors.\"\"\"\n",
    "    return {\n",
    "        \"ExactMolWt\": float(Descriptors.ExactMolWt(mol)),\n",
    "        \"MolLogP\": float(Descriptors.MolLogP(mol)),\n",
    "        \"TPSA\": float(CalcTPSA(mol)),\n",
    "        \"NumHDonors\": int(Descriptors.NumHDonors(mol)),\n",
    "        \"NumHAcceptors\": int(Descriptors.NumHAcceptors(mol)),\n",
    "        \"NumRotatableBonds\": int(Descriptors.NumRotatableBonds(mol)),\n",
    "        \"HeavyAtomCount\": int(mol.GetNumHeavyAtoms()),\n",
    "        \"FracCSP3\": float(Descriptors.FractionCSP3(mol)),\n",
    "        \"RingCount\": int(Descriptors.RingCount(mol)) if hasattr(Descriptors, 'RingCount') else 0,\n",
    "        \"AromaticRings\": int(len([r for r in mol.GetRingInfo().AtomRings()\n",
    "                                  if any(mol.GetAtomWithIdx(i).GetIsAromatic() for i in r)]))\n",
    "    }\n",
    "\n",
    "# -------------------- Compute descriptors --------------------\n",
    "desc_rows = []\n",
    "valid_smiles = []\n",
    "valid_idx = []\n",
    "\n",
    "for i, s in enumerate(df[smiles_col].astype(str)):\n",
    "    mol = mol_from_smiles_safe(s)\n",
    "    if mol is None:\n",
    "        desc_rows.append({col: np.nan for col in [\n",
    "            \"ExactMolWt\",\"MolLogP\",\"TPSA\",\"NumHDonors\",\"NumHAcceptors\",\n",
    "            \"NumRotatableBonds\",\"HeavyAtomCount\",\"FracCSP3\",\"RingCount\",\"AromaticRings\"\n",
    "        ]})\n",
    "        valid_smiles.append(False)\n",
    "        continue\n",
    "\n",
    "    desc = compute_rdkit_descs(mol)\n",
    "    desc[\"LogP_over_MolWt\"] = desc[\"MolLogP\"] / (desc[\"ExactMolWt\"] + 1e-9)\n",
    "    desc[\"TPSA_per_Heavy\"]  = desc[\"TPSA\"] / (desc[\"HeavyAtomCount\"] + 1e-9)\n",
    "    desc_rows.append(desc)\n",
    "    valid_smiles.append(True)\n",
    "    valid_idx.append(i)\n",
    "\n",
    "desc_df = pd.DataFrame(desc_rows)\n",
    "\n",
    "# -------------------- Filter only valid molecules --------------------\n",
    "df[\"_mol_valid\"] = valid_smiles\n",
    "valid_df = df[df[\"_mol_valid\"]].reset_index(drop=True)\n",
    "desc_df = desc_df.loc[valid_df.index].reset_index(drop=True)\n",
    "\n",
    "print(f\"✅ Parsed {len(valid_df)} valid molecules out of {len(df)} total.\")\n",
    "\n",
    "# -------------------- Robust scaling --------------------\n",
    "scaler = RobustScaler()\n",
    "to_scale = desc_df.columns.tolist()\n",
    "scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(desc_df.fillna(0)),\n",
    "    columns=[c + \"_scaled\" for c in to_scale]\n",
    ")\n",
    "desc_df = pd.concat([desc_df, scaled], axis=1)\n",
    "\n",
    "# -------------------- Merge + Save --------------------\n",
    "final_df = pd.concat([valid_df.reset_index(drop=True), desc_df.reset_index(drop=True)], axis=1)\n",
    "final_df.to_excel(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(\"\\n✅ Descriptors successfully computed and saved!\")\n",
    "print(f\"Saved → {OUTPUT_PATH}\")\n",
    "print(f\"Final rows: {len(final_df)} (only valid molecules retained)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82e1f576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 2384 rows from cleaned dataset.\n",
      "Detected label column: Label\n",
      "✅ Converted label column → numeric (unique: [0 1])\n",
      "Class weights: {0: 0.9840041279669762, 1: 1.0165245202558635}\n",
      "\n",
      "🔍 Tuning LightGBM meta-learner with Optuna...\n",
      "Training base model: cat\n",
      "Training base model: xgb\n",
      "Training base model: lgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:34,547] A new study created in memory with name: no-name-71518cae-1743-4053-814f-17eb6fcdf9c6\n",
      "Best trial: 0. Best value: 0.666044:   2%|▎         | 1/40 [00:00<00:25,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:35,207] Trial 0 finished with value: 0.6660438027214625 and parameters: {'learning_rate': 0.06199716442476227, 'num_leaves': 82, 'max_depth': 4, 'min_child_samples': 8, 'reg_alpha': 0.5603000564280312, 'reg_lambda': 1.5700417306235441, 'subsample': 0.654241771329273, 'colsample_bytree': 0.7522029013090307, 'n_estimators': 743}. Best is trial 0 with value: 0.6660438027214625.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.687539:   5%|▌         | 2/40 [00:00<00:14,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:35,416] Trial 1 finished with value: 0.6875391275391275 and parameters: {'learning_rate': 0.09885069885301165, 'num_leaves': 30, 'max_depth': 3, 'min_child_samples': 12, 'reg_alpha': 1.6704443059451843, 'reg_lambda': 1.7906646017340222, 'subsample': 0.8171191871770482, 'colsample_bytree': 0.7865016145027182, 'n_estimators': 279}. Best is trial 1 with value: 0.6875391275391275.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.687539:   8%|▊         | 3/40 [00:01<00:17,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:35,970] Trial 2 finished with value: 0.6594508189734454 and parameters: {'learning_rate': 0.09561054069075255, 'num_leaves': 76, 'max_depth': 5, 'min_child_samples': 34, 'reg_alpha': 1.201462172265009, 'reg_lambda': 0.1741833467295888, 'subsample': 0.7439862362252283, 'colsample_bytree': 0.7626870184517123, 'n_estimators': 548}. Best is trial 1 with value: 0.6875391275391275.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.687539:  10%|█         | 4/40 [00:01<00:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:36,432] Trial 3 finished with value: 0.6770944107848565 and parameters: {'learning_rate': 0.07089045417268114, 'num_leaves': 69, 'max_depth': 6, 'min_child_samples': 15, 'reg_alpha': 1.8959880295325844, 'reg_lambda': 1.8934625104609402, 'subsample': 0.62538684245775, 'colsample_bytree': 0.9315622384330172, 'n_estimators': 689}. Best is trial 1 with value: 0.6875391275391275.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.687539:  12%|█▎        | 5/40 [00:03<00:27,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:37,818] Trial 4 finished with value: 0.6398548971814529 and parameters: {'learning_rate': 0.05232495863806649, 'num_leaves': 46, 'max_depth': 10, 'min_child_samples': 10, 'reg_alpha': 0.017154589993106706, 'reg_lambda': 1.4655229202063014, 'subsample': 0.9379441017994345, 'colsample_bytree': 0.9901333798587256, 'n_estimators': 638}. Best is trial 1 with value: 0.6875391275391275.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.687539:  15%|█▌        | 6/40 [00:04<00:28,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:38,717] Trial 5 finished with value: 0.6570200853670839 and parameters: {'learning_rate': 0.05585868235658767, 'num_leaves': 60, 'max_depth': 7, 'min_child_samples': 16, 'reg_alpha': 1.0941667729620481, 'reg_lambda': 0.7718762790691718, 'subsample': 0.6487847013699135, 'colsample_bytree': 0.9778922400678919, 'n_estimators': 484}. Best is trial 1 with value: 0.6875391275391275.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.687539:  18%|█▊        | 7/40 [00:04<00:25,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:39,359] Trial 6 finished with value: 0.6598387125003907 and parameters: {'learning_rate': 0.07503722075993106, 'num_leaves': 10, 'max_depth': 7, 'min_child_samples': 16, 'reg_alpha': 1.2023701555807986, 'reg_lambda': 0.44335159312928263, 'subsample': 0.7649192325809059, 'colsample_bytree': 0.8354563760260446, 'n_estimators': 729}. Best is trial 1 with value: 0.6875391275391275.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.691543:  20%|██        | 8/40 [00:05<00:21,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:39,842] Trial 7 finished with value: 0.6915425851482426 and parameters: {'learning_rate': 0.020356005576004116, 'num_leaves': 113, 'max_depth': 5, 'min_child_samples': 26, 'reg_alpha': 0.7254076754369592, 'reg_lambda': 1.146028896014474, 'subsample': 0.6738807352959, 'colsample_bytree': 0.7692740577623807, 'n_estimators': 467}. Best is trial 7 with value: 0.6915425851482426.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.691543:  22%|██▎       | 9/40 [00:06<00:25,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:40,936] Trial 8 finished with value: 0.6534481709801382 and parameters: {'learning_rate': 0.039244952119156545, 'num_leaves': 28, 'max_depth': 6, 'min_child_samples': 13, 'reg_alpha': 0.8571095395139734, 'reg_lambda': 0.23195107503935564, 'subsample': 0.9665029652256819, 'colsample_bytree': 0.9840661511068995, 'n_estimators': 746}. Best is trial 7 with value: 0.6915425851482426.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.691543:  25%|██▌       | 10/40 [00:06<00:20,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:41,363] Trial 9 finished with value: 0.6664656124959155 and parameters: {'learning_rate': 0.06287030261838968, 'num_leaves': 77, 'max_depth': 5, 'min_child_samples': 13, 'reg_alpha': 1.2877157783653597, 'reg_lambda': 1.8953208677844464, 'subsample': 0.8651122437557228, 'colsample_bytree': 0.9658992659261589, 'n_estimators': 357}. Best is trial 7 with value: 0.6915425851482426.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.703347:  30%|███       | 12/40 [00:07<00:16,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:42,237] Trial 10 finished with value: 0.6807755611181177 and parameters: {'learning_rate': 0.010522735180920206, 'num_leaves': 125, 'max_depth': 9, 'min_child_samples': 27, 'reg_alpha': 0.3710688645808564, 'reg_lambda': 1.102260229886931, 'subsample': 0.7016610279663327, 'colsample_bytree': 0.6065941833125782, 'n_estimators': 427}. Best is trial 7 with value: 0.6915425851482426.\n",
      "[I 2025-10-24 15:00:42,411] Trial 11 finished with value: 0.7033471953418681 and parameters: {'learning_rate': 0.02004938884310041, 'num_leaves': 113, 'max_depth': 3, 'min_child_samples': 23, 'reg_alpha': 1.7914712081923825, 'reg_lambda': 1.1427571468076583, 'subsample': 0.842211804333195, 'colsample_bytree': 0.6897152204232624, 'n_estimators': 205}. Best is trial 11 with value: 0.7033471953418681.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.705561:  35%|███▌      | 14/40 [00:08<00:09,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:42,582] Trial 12 finished with value: 0.7055607544361966 and parameters: {'learning_rate': 0.016086105686827765, 'num_leaves': 120, 'max_depth': 3, 'min_child_samples': 24, 'reg_alpha': 1.5858255324754826, 'reg_lambda': 1.0775515746551745, 'subsample': 0.8618473604801644, 'colsample_bytree': 0.6972084799168533, 'n_estimators': 206}. Best is trial 12 with value: 0.7055607544361966.\n",
      "[I 2025-10-24 15:00:42,761] Trial 13 finished with value: 0.705286394170535 and parameters: {'learning_rate': 0.029314702512827126, 'num_leaves': 105, 'max_depth': 3, 'min_child_samples': 23, 'reg_alpha': 1.543197097184094, 'reg_lambda': 0.7236241581252599, 'subsample': 0.8883658473270838, 'colsample_bytree': 0.6719363523312315, 'n_estimators': 220}. Best is trial 12 with value: 0.7055607544361966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.706413:  38%|███▊      | 15/40 [00:08<00:07,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:42,929] Trial 14 finished with value: 0.7064127342941597 and parameters: {'learning_rate': 0.035676925114134325, 'num_leaves': 101, 'max_depth': 3, 'min_child_samples': 34, 'reg_alpha': 1.5250452807123347, 'reg_lambda': 0.6221102512627605, 'subsample': 0.9114103772805621, 'colsample_bytree': 0.6525971681305379, 'n_estimators': 208}. Best is trial 14 with value: 0.7064127342941597.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.706413:  40%|████      | 16/40 [00:08<00:07,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:43,213] Trial 15 finished with value: 0.6977874618589389 and parameters: {'learning_rate': 0.03866765475579378, 'num_leaves': 95, 'max_depth': 4, 'min_child_samples': 39, 'reg_alpha': 1.4751776425658842, 'reg_lambda': 0.776574347630344, 'subsample': 0.9121834840586001, 'colsample_bytree': 0.609001437986598, 'n_estimators': 299}. Best is trial 14 with value: 0.7064127342941597.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.706413:  42%|████▎     | 17/40 [00:09<00:08,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:43,752] Trial 16 finished with value: 0.680589435257074 and parameters: {'learning_rate': 0.03882754069453577, 'num_leaves': 124, 'max_depth': 8, 'min_child_samples': 32, 'reg_alpha': 1.9852415884136623, 'reg_lambda': 0.5204199700237895, 'subsample': 0.9930065801972761, 'colsample_bytree': 0.6842221965854015, 'n_estimators': 351}. Best is trial 14 with value: 0.7064127342941597.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  45%|████▌     | 18/40 [00:09<00:07,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:43,998] Trial 17 finished with value: 0.7070161091892023 and parameters: {'learning_rate': 0.02524994342060852, 'num_leaves': 99, 'max_depth': 4, 'min_child_samples': 40, 'reg_alpha': 1.4151194418994073, 'reg_lambda': 1.3637633788981742, 'subsample': 0.7981530687555227, 'colsample_bytree': 0.71652552962733, 'n_estimators': 266}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  48%|████▊     | 19/40 [00:09<00:07,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:44,355] Trial 18 finished with value: 0.6887611649870621 and parameters: {'learning_rate': 0.04693817710816048, 'num_leaves': 96, 'max_depth': 4, 'min_child_samples': 39, 'reg_alpha': 1.4672059822480044, 'reg_lambda': 1.5245823754786836, 'subsample': 0.7778052912039132, 'colsample_bytree': 0.845993483052754, 'n_estimators': 386}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  50%|█████     | 20/40 [00:10<00:06,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:44,613] Trial 19 finished with value: 0.7023553302166714 and parameters: {'learning_rate': 0.029913759152095692, 'num_leaves': 92, 'max_depth': 4, 'min_child_samples': 33, 'reg_alpha': 0.9280450118396681, 'reg_lambda': 1.405558292564839, 'subsample': 0.8104813375459063, 'colsample_bytree': 0.6431833885425818, 'n_estimators': 275}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  55%|█████▌    | 22/40 [00:10<00:05,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:45,180] Trial 20 finished with value: 0.6851167345602983 and parameters: {'learning_rate': 0.02986002852652253, 'num_leaves': 59, 'max_depth': 5, 'min_child_samples': 37, 'reg_alpha': 1.351231501896601, 'reg_lambda': 0.9169651527476932, 'subsample': 0.7244240831400193, 'colsample_bytree': 0.7216135477927668, 'n_estimators': 559}. Best is trial 17 with value: 0.7070161091892023.\n",
      "[I 2025-10-24 15:00:45,347] Trial 21 finished with value: 0.7048503408067668 and parameters: {'learning_rate': 0.010657403962395055, 'num_leaves': 109, 'max_depth': 3, 'min_child_samples': 28, 'reg_alpha': 1.693442028597634, 'reg_lambda': 1.3343741874519996, 'subsample': 0.8582180216090722, 'colsample_bytree': 0.724142903307402, 'n_estimators': 202}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  57%|█████▊    | 23/40 [00:11<00:04,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:45,566] Trial 22 finished with value: 0.7049240457407664 and parameters: {'learning_rate': 0.016895420472019942, 'num_leaves': 128, 'max_depth': 3, 'min_child_samples': 30, 'reg_alpha': 1.6044105250669904, 'reg_lambda': 0.5587783338286391, 'subsample': 0.9092915765113813, 'colsample_bytree': 0.6493255509807785, 'n_estimators': 273}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  60%|██████    | 24/40 [00:11<00:04,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:45,868] Trial 23 finished with value: 0.7013051338392013 and parameters: {'learning_rate': 0.023937561213773047, 'num_leaves': 89, 'max_depth': 4, 'min_child_samples': 20, 'reg_alpha': 1.4342081799423199, 'reg_lambda': 0.9738436259364901, 'subsample': 0.8298743216681534, 'colsample_bytree': 0.7207897328923811, 'n_estimators': 315}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  62%|██████▎   | 25/40 [00:11<00:04,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:46,069] Trial 24 finished with value: 0.698088554927767 and parameters: {'learning_rate': 0.034317456605233276, 'num_leaves': 101, 'max_depth': 3, 'min_child_samples': 36, 'reg_alpha': 1.779711965299807, 'reg_lambda': 1.2168101356723853, 'subsample': 0.8835125722165244, 'colsample_bytree': 0.8217623108418951, 'n_estimators': 247}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  65%|██████▌   | 26/40 [00:11<00:03,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:46,376] Trial 25 finished with value: 0.6897046594103007 and parameters: {'learning_rate': 0.04482444037580369, 'num_leaves': 117, 'max_depth': 4, 'min_child_samples': 40, 'reg_alpha': 1.1146001920260253, 'reg_lambda': 0.9285873313669556, 'subsample': 0.7934464244540088, 'colsample_bytree': 0.6482613527257135, 'n_estimators': 331}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  68%|██████▊   | 27/40 [00:12<00:04,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:46,877] Trial 26 finished with value: 0.691150295181913 and parameters: {'learning_rate': 0.02550291582138352, 'num_leaves': 84, 'max_depth': 6, 'min_child_samples': 36, 'reg_alpha': 1.2940999072309014, 'reg_lambda': 1.6615374618646024, 'subsample': 0.9415565862319307, 'colsample_bytree': 0.8684755273026193, 'n_estimators': 400}. Best is trial 17 with value: 0.7070161091892023.\n",
      "[I 2025-10-24 15:00:47,076] Trial 27 finished with value: 0.7042317071956957 and parameters: {'learning_rate': 0.014665500573860792, 'num_leaves': 102, 'max_depth': 3, 'min_child_samples': 5, 'reg_alpha': 1.8274583974609895, 'reg_lambda': 1.2671400990294555, 'subsample': 0.8971010546930428, 'colsample_bytree': 0.7049404137417653, 'n_estimators': 243}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  72%|███████▎  | 29/40 [00:12<00:03,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:47,364] Trial 28 finished with value: 0.7009075751333317 and parameters: {'learning_rate': 0.023598209734529314, 'num_leaves': 122, 'max_depth': 5, 'min_child_samples': 30, 'reg_alpha': 1.6178272114624135, 'reg_lambda': 0.31960313972781407, 'subsample': 0.9395627654224752, 'colsample_bytree': 0.7450546821108581, 'n_estimators': 246}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  75%|███████▌  | 30/40 [00:13<00:02,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:47,572] Trial 29 finished with value: 0.7018448404409178 and parameters: {'learning_rate': 0.03399485197873158, 'num_leaves': 85, 'max_depth': 4, 'min_child_samples': 19, 'reg_alpha': 0.5261414911482166, 'reg_lambda': 0.6707554012627472, 'subsample': 0.858245582902364, 'colsample_bytree': 0.6686597433606383, 'n_estimators': 203}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  78%|███████▊  | 31/40 [00:13<00:02,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:47,883] Trial 30 finished with value: 0.689133610943426 and parameters: {'learning_rate': 0.04595295470318851, 'num_leaves': 116, 'max_depth': 3, 'min_child_samples': 25, 'reg_alpha': 1.007468776304797, 'reg_lambda': 1.6981773252253234, 'subsample': 0.997285158227086, 'colsample_bytree': 0.6262911191425249, 'n_estimators': 438}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  80%|████████  | 32/40 [00:13<00:02,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:48,115] Trial 31 finished with value: 0.698982491603467 and parameters: {'learning_rate': 0.031155778985226992, 'num_leaves': 105, 'max_depth': 4, 'min_child_samples': 22, 'reg_alpha': 1.5406667106308445, 'reg_lambda': 0.7013407198373189, 'subsample': 0.8738732022743088, 'colsample_bytree': 0.6780362908522435, 'n_estimators': 239}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  82%|████████▎ | 33/40 [00:13<00:01,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:48,339] Trial 32 finished with value: 0.7042559689199537 and parameters: {'learning_rate': 0.02587733821296779, 'num_leaves': 105, 'max_depth': 3, 'min_child_samples': 23, 'reg_alpha': 1.6720068594536928, 'reg_lambda': 0.8567840036426746, 'subsample': 0.836944098298383, 'colsample_bytree': 0.6619927305384571, 'n_estimators': 300}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  85%|████████▌ | 34/40 [00:13<00:01,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:48,549] Trial 33 finished with value: 0.7055422322467703 and parameters: {'learning_rate': 0.01738791049131766, 'num_leaves': 98, 'max_depth': 3, 'min_child_samples': 19, 'reg_alpha': 1.3744295989403286, 'reg_lambda': 1.0900359590869169, 'subsample': 0.9081894844867879, 'colsample_bytree': 0.7950247309813991, 'n_estimators': 239}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  88%|████████▊ | 35/40 [00:14<00:01,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:48,835] Trial 34 finished with value: 0.7023658906793167 and parameters: {'learning_rate': 0.01588017655194701, 'num_leaves': 95, 'max_depth': 4, 'min_child_samples': 20, 'reg_alpha': 1.3732685680178944, 'reg_lambda': 1.0652143666882665, 'subsample': 0.9153463441149629, 'colsample_bytree': 0.7931864474084036, 'n_estimators': 269}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  90%|█████████ | 36/40 [00:14<00:01,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:49,224] Trial 35 finished with value: 0.6972185605619488 and parameters: {'learning_rate': 0.01894968765971091, 'num_leaves': 70, 'max_depth': 3, 'min_child_samples': 35, 'reg_alpha': 1.2733599396319124, 'reg_lambda': 0.05704484492548334, 'subsample': 0.9674084851797421, 'colsample_bytree': 0.7517704159875056, 'n_estimators': 563}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  92%|█████████▎| 37/40 [00:15<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:49,605] Trial 36 finished with value: 0.6834836353381805 and parameters: {'learning_rate': 0.08784932102691517, 'num_leaves': 119, 'max_depth': 4, 'min_child_samples': 31, 'reg_alpha': 1.9967319547023397, 'reg_lambda': 1.3266554070617613, 'subsample': 0.8049974751915682, 'colsample_bytree': 0.7763011563223388, 'n_estimators': 616}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  95%|█████████▌| 38/40 [00:15<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:50,043] Trial 37 finished with value: 0.7032488149573799 and parameters: {'learning_rate': 0.010662119497714567, 'num_leaves': 78, 'max_depth': 5, 'min_child_samples': 18, 'reg_alpha': 1.097291572138515, 'reg_lambda': 1.6099389058215885, 'subsample': 0.9256926150600777, 'colsample_bytree': 0.870281302557751, 'n_estimators': 336}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016:  98%|█████████▊| 39/40 [00:16<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:50,785] Trial 38 finished with value: 0.6688158954156773 and parameters: {'learning_rate': 0.058267568198118846, 'num_leaves': 57, 'max_depth': 10, 'min_child_samples': 9, 'reg_alpha': 1.690650033670581, 'reg_lambda': 1.0256757840595734, 'subsample': 0.7315080307209844, 'colsample_bytree': 0.9165688787463008, 'n_estimators': 294}. Best is trial 17 with value: 0.7070161091892023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.707016: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 15:00:51,339] Trial 39 finished with value: 0.6953700203603708 and parameters: {'learning_rate': 0.02344759211306757, 'num_leaves': 110, 'max_depth': 3, 'min_child_samples': 17, 'reg_alpha': 1.1453357662866124, 'reg_lambda': 1.4331193228517263, 'subsample': 0.7596880326700755, 'colsample_bytree': 0.8104774974283124, 'n_estimators': 784}. Best is trial 17 with value: 0.7070161091892023.\n",
      "Best meta-learner params: {'learning_rate': 0.02524994342060852, 'num_leaves': 99, 'max_depth': 4, 'min_child_samples': 40, 'reg_alpha': 1.4151194418994073, 'reg_lambda': 1.3637633788981742, 'subsample': 0.7981530687555227, 'colsample_bytree': 0.71652552962733, 'n_estimators': 266}\n",
      "\n",
      "📊 Final Performance:\n",
      "ROC-AUC: 0.7580182873219624\n",
      "Accuracy: 0.6477987421383647\n",
      "Best F1: 0.7152542372881356 Threshold: 0.3034633505515998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.40      0.54       242\n",
      "           1       0.59      0.90      0.72       235\n",
      "\n",
      "    accuracy                           0.65       477\n",
      "   macro avg       0.70      0.65      0.63       477\n",
      "weighted avg       0.70      0.65      0.63       477\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'selected_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 170\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# -------------------- SAVE MODEL --------------------\u001b[39;00m\n\u001b[32m    169\u001b[39m artifact = {\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mselected_features\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mselected_features\u001b[49m,\n\u001b[32m    171\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbase_models\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m\"\u001b[39m: cat, \u001b[33m\"\u001b[39m\u001b[33mxgb\u001b[39m\u001b[33m\"\u001b[39m: xg, \u001b[33m\"\u001b[39m\u001b[33mlgb\u001b[39m\u001b[33m\"\u001b[39m: lgbm},\n\u001b[32m    172\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m: meta,\n\u001b[32m    173\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbest_params\u001b[39m\u001b[33m\"\u001b[39m: best_params,\n\u001b[32m    174\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mthreshold\u001b[39m\u001b[33m\"\u001b[39m: best_thr,\n\u001b[32m    175\u001b[39m }\n\u001b[32m    176\u001b[39m joblib.dump(artifact, \u001b[33m\"\u001b[39m\u001b[33mbest_ensemble_final_v4.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ Saved model → best_ensemble_final_v4.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'selected_features' is not defined"
     ]
    }
   ],
   "source": [
    "# improved_hepato_model_v4.py\n",
    "# ✅ Chemically informed ensemble using descriptor features only\n",
    "# ✅ Uses clean file: reference_database(Hepato)_with_descs_fixed.xlsx\n",
    "# ✅ Includes Optuna-based hyperparameter tuning for LightGBM meta-learner\n",
    "\n",
    "import warnings, joblib, optuna\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_recall_curve, classification_report\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# -------------------- CONFIG --------------------\n",
    "PATH = \"reference_database(Hepato)_with_descs_fixed.xlsx\"\n",
    "RANDOM_STATE = 42\n",
    "OPTUNA_TRIALS = 40\n",
    "\n",
    "# -------------------- LOAD DATA --------------------\n",
    "# -------------------- LOAD DATA --------------------\n",
    "df = pd.read_excel(PATH)\n",
    "print(f\"✅ Loaded {len(df)} rows from cleaned dataset.\")\n",
    "\n",
    "# Detect label column automatically\n",
    "label_col = next(\n",
    "    (c for c in df.columns if any(x in str(c).lower() for x in ['label','tox','dili','final','class'])),\n",
    "    None\n",
    ")\n",
    "if label_col is None:\n",
    "    raise RuntimeError(\"❌ Label column not found. Rename one column to include 'label' or 'tox'.\")\n",
    "\n",
    "print(f\"Detected label column: {label_col}\")\n",
    "\n",
    "# ---- Fix labels ----\n",
    "def map_label(v):\n",
    "    s = str(v).strip().lower()\n",
    "    if s in ['1', 'true', 'pos', 'positive', 'yes', 'y', 'p']:\n",
    "        return 1\n",
    "    elif s in ['0', 'false', 'neg', 'negative', 'no', 'n']:\n",
    "        return 0\n",
    "    else:\n",
    "        try:\n",
    "            return int(float(s))\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "# Apply label mapping\n",
    "df[label_col] = df[label_col].apply(map_label)\n",
    "df = df.dropna(subset=[label_col]).reset_index(drop=True)\n",
    "y = df[label_col].astype(int).values\n",
    "\n",
    "print(f\"✅ Converted label column → numeric (unique: {np.unique(y)})\")\n",
    "\n",
    "\n",
    "# -------------------- TRAIN/TEST SPLIT --------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------- CLASS WEIGHTS --------------------\n",
    "cw = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "cw_dict = {int(c): float(cw[i]) for i, c in enumerate(np.unique(y_train))}\n",
    "print(\"Class weights:\", cw_dict)\n",
    "\n",
    "# -------------------- BASE MODELS --------------------\n",
    "cat = CatBoostClassifier(iterations=1000, learning_rate=0.03, depth=7,\n",
    "                         class_weights=list(cw), random_seed=RANDOM_STATE,\n",
    "                         verbose=0, l2_leaf_reg=5)\n",
    "\n",
    "xg = xgb.XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=7,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.5,\n",
    "    scale_pos_weight=cw_dict[0] / cw_dict[1],\n",
    "    eval_metric='logloss',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=cw_dict,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# -------------------- STACKING WITH OPTUNA TUNING --------------------\n",
    "print(\"\\n🔍 Tuning LightGBM meta-learner with Optuna...\")\n",
    "\n",
    "# Create out-of-fold predictions for meta-training\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "oof = np.zeros((X_train.shape[0], 3))\n",
    "test_preds = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "for i, (name, est) in enumerate([('cat', cat), ('xgb', xg), ('lgb', lgbm)]):\n",
    "    print(f\"Training base model: {name}\")\n",
    "    fold_probs = np.zeros((X_test.shape[0], cv.get_n_splits()))\n",
    "    o = np.zeros(X_train.shape[0])\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "        X_tr, X_val = X_train[tr_idx], X_train[val_idx]\n",
    "        y_tr, y_val = y_train[tr_idx], y_train[val_idx]\n",
    "        e = est.__class__(**est.get_params())\n",
    "        e.fit(X_tr, y_tr)\n",
    "        o[val_idx] = e.predict_proba(X_val)[:, 1]\n",
    "        fold_probs[:, fold] = e.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    oof[:, i] = o\n",
    "    test_preds[:, i] = fold_probs.mean(axis=1)\n",
    "\n",
    "# -------------------- OPTUNA META MODEL --------------------\n",
    "def optuna_objective(trial):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 128),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 40),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 2.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 2.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 800),\n",
    "        \"random_state\": RANDOM_STATE\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    scores = []\n",
    "    for tr_idx, val_idx in cv.split(oof, y_train):\n",
    "        model.fit(oof[tr_idx], y_train[tr_idx])\n",
    "        pred = (model.predict_proba(oof[val_idx])[:, 1] >= 0.5).astype(int)\n",
    "        scores.append(f1_score(y_train[val_idx], pred))\n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(optuna_objective, n_trials=OPTUNA_TRIALS, show_progress_bar=True)\n",
    "best_params = study.best_params\n",
    "print(\"Best meta-learner params:\", best_params)\n",
    "\n",
    "# -------------------- META MODEL TRAINING --------------------\n",
    "meta = lgb.LGBMClassifier(**best_params)\n",
    "meta.fit(oof, y_train)\n",
    "meta_preds = meta.predict_proba(test_preds)[:, 1]\n",
    "\n",
    "# -------------------- THRESHOLD TUNING --------------------\n",
    "p, r, th = precision_recall_curve(y_test, meta_preds)\n",
    "f1s = 2 * p * r / (p + r + 1e-12)\n",
    "best_thr = float(th[np.nanargmax(f1s)]) if len(th) > 0 else 0.5\n",
    "\n",
    "y_pred = (meta_preds >= best_thr).astype(int)\n",
    "print(\"\\n📊 Final Performance:\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, meta_preds))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Best F1:\", f1_score(y_test, y_pred), \"Threshold:\", best_thr)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# -------------------- SAVE MODEL --------------------\n",
    "artifact = {\n",
    "    \"selected_features\": selected_features,\n",
    "    \"base_models\": {\"cat\": cat, \"xgb\": xg, \"lgb\": lgbm},\n",
    "    \"meta\": meta,\n",
    "    \"best_params\": best_params,\n",
    "    \"threshold\": best_thr,\n",
    "}\n",
    "joblib.dump(artifact, \"best_ensemble_final_v4.pkl\")\n",
    "print(\"\\n✅ Saved model → best_ensemble_final_v4.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
